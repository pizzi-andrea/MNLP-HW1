{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5df55e1",
   "metadata": {},
   "source": [
    "## The CrossTree\n",
    "\n",
    "Voting Schema with multiple binary classification trees. The network implements a voting scheme based on three different trees:\n",
    "\n",
    "* Cultural **Agnostic-Rappresentative** tree\n",
    "* Cultural **Agnostic-Exclusive** tree\n",
    "* Cultural **Exclusive-Rappresentative** tree\n",
    "\n",
    "the most voted class will be the predicted class.\n",
    "\n",
    "### Training Phase\n",
    "\n",
    "The training process is quite standard and straight-forward: given the n G_features we want to directly predict the associated class.\n",
    "\n",
    "### Employment Phase\n",
    "\n",
    "The training model will be inserted in a wider model called X and utilized as a function for the computation of the G_Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b724d1",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afebd71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/miniconda3/envs/MNLP/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from CU_Dataset_Factory import Hf_Loader, CU_Dataset_Factory\n",
    "\n",
    "def onehot_encode(\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    cat_cols: list[str]|None = None,\n",
    "    num_cols: list[str]|None = None,\n",
    "    sparse: bool = False\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, OneHotEncoder]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Applies One-Hot Encoding to df_train and df_test guaranteeing the same\n",
    "    set of columns, even if train is missing categories who are in the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_train : pd.DataFrame\n",
    "        Training DataFrame.\n",
    "    df_test : pd.DataFrame\n",
    "        Testing DataFrame.\n",
    "    cat_cols : list[str], optional\n",
    "        List of categorical columns to encode.\n",
    "        If None, all columns of type 'object' are taken.\n",
    "    num_cols : list[str], optional\n",
    "        List of numerical (or non-categorical) columns to preserve.\n",
    "        If None, all columns not in cat_cols are taken. \n",
    "    handle_unknown : str, default=\"ignore\"\n",
    "        Beahavior on unknown values in test (typically \"ignore\").\n",
    "    sparse : bool, default=False\n",
    "        If True, returns sparse matrix, otherwise dense.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_train_enc : pd.DataFrame\n",
    "        Training DataFrame with One-Hot Encoding + original num_cols.\n",
    "    df_test_enc : pd.DataFrame\n",
    "        Testing DataFrame with One-Hot Encoding + original num_cols.\n",
    "    encoder : OneHotEncoder\n",
    "        The fitted OneHotEncoder object, useful for future transform.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Identify category and numerical columns (if not given)\n",
    "    if cat_cols is None:\n",
    "        cat_cols = df_train.select_dtypes(include=\"object\").columns.tolist()\n",
    "    if num_cols is None:\n",
    "        num_cols = [c for c in df_train.columns if c not in cat_cols]\n",
    "\n",
    "    # 2) Fit encoder on all category data (train + test)\n",
    "    all_cats = pd.concat([df_train[cat_cols], df_test[cat_cols]], \n",
    "                         axis=0, ignore_index=True)\n",
    "    encoder = OneHotEncoder(\n",
    "        sparse_output=sparse\n",
    "    ).fit(all_cats)\n",
    "\n",
    "    # 3) Transform separatly train and test\n",
    "    X_train_ohe = encoder.transform(df_train[cat_cols])\n",
    "    X_test_ohe  = encoder.transform(df_test[cat_cols])\n",
    "\n",
    "    # 4) Name the new columns\n",
    "    ohe_cols = encoder.get_feature_names_out(cat_cols).tolist()\n",
    "\n",
    "    # 5) Compose the final DataFrames\n",
    "    df_train_enc = pd.DataFrame(\n",
    "        np.hstack([X_train_ohe.toarray() if sparse else X_train_ohe,\n",
    "                   df_train[num_cols].values]), # type: ignore\n",
    "        columns=ohe_cols + num_cols,\n",
    "        index=df_train.index\n",
    "    )\n",
    "    df_test_enc = pd.DataFrame(\n",
    "        np.hstack([X_test_ohe.toarray() if sparse else X_test_ohe,\n",
    "                   df_test[num_cols].values]),\n",
    "        columns=ohe_cols + num_cols,\n",
    "        index=df_test.index\n",
    "    )\n",
    "\n",
    "    return df_train_enc[ohe_cols], df_test_enc[ohe_cols], encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5133b41",
   "metadata": {},
   "source": [
    "## Produce the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75c3161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cultural Dataset argumentation start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:00<00:00, 460.99it/s]\n",
      "copy dataset: 100%|██████████| 5/5 [00:00<00:00, 1175.47it/s]\n",
      "n_mod:   0%|          | 0/6251 [00:06<?, ?it/s, batch=1]        "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m train_l = Hf_Loader(\u001b[33m\"\u001b[39m\u001b[33msapienzanlp/nlp2025_hw1_cultural_dataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m validation_l = Hf_Loader(\u001b[33m\"\u001b[39m\u001b[33msapienzanlp/nlp2025_hw1_cultural_dataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mfactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain.tsv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlanguages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_langs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreference\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_mod\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mback_links\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m factory.produce(validation_l, \u001b[33m'\u001b[39m\u001b[33mvalidation.tsv\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33mlanguages\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnum_langs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mreference\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mn_mod\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mback_links\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m16\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEnd process\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/MNLP/MNLP-HW1/src/CU_Dataset_Factory.py:359\u001b[39m, in \u001b[36mCU_Dataset_Factory.produce\u001b[39m\u001b[34m(self, loader, out_file, enable_feature, targe_feature, batch_s, load, encoding)\u001b[39m\n\u001b[32m    357\u001b[39m dataset = dataset.drop([\u001b[33m\"\u001b[39m\u001b[33mitem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m], axis=\u001b[32m1\u001b[39m)\n\u001b[32m    358\u001b[39m \u001b[38;5;66;03m# Function that calls back __produce and returns the new dataset\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m prc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__produce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarge_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[38;5;28mself\u001b[39m.__save_with_format(prc, out_file)\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/MNLP/MNLP-HW1/src/CU_Dataset_Factory.py:236\u001b[39m, in \u001b[36mCU_Dataset_Factory.__produce\u001b[39m\u001b[34m(self, dataset, enable_feature, targe_feature, batch_s, encode)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    233\u001b[39m     feature == \u001b[33m\"\u001b[39m\u001b[33mn_mod\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    234\u001b[39m ):  \u001b[38;5;66;03m# count the mean number of edits in a specific time interval\u001b[39;00m\n\u001b[32m    235\u001b[39m     join_fe = \u001b[33m\"\u001b[39m\u001b[33mwiki_name\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     r = \u001b[43mnum_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mjoin_fe\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;66;03m# NUM_VISITS\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# elif feature == \"n_visits\": # count the mean number of visits per day in a time interval\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m#     join_fe = 'wiki_name'\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m \n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# NUM_LANGS\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m feature == \u001b[33m\"\u001b[39m\u001b[33mnum_langs\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/MNLP/MNLP-HW1/src/features.py:539\u001b[39m, in \u001b[36mnum_mod\u001b[39m\u001b[34m(queries, conn)\u001b[39m\n\u001b[32m    528\u001b[39m params = {\n\u001b[32m    529\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    530\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    534\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtitles\u001b[39m\u001b[33m\"\u001b[39m: title\n\u001b[32m    535\u001b[39m }\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;66;03m# Execute the call\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_wikipedia\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m     data = response.get(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    541\u001b[39m     pages = data.get(\u001b[33m\"\u001b[39m\u001b[33mpages\u001b[39m\u001b[33m\"\u001b[39m, {})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/MNLP/MNLP-HW1/src/Connection.py:53\u001b[39m, in \u001b[36mWiki_high_conn.get_wikipedia\u001b[39m\u001b[34m(self, queries, params, lang)\u001b[39m\n\u001b[32m     50\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     51\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33mtitles\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m|\u001b[39m\u001b[33m\"\u001b[39m.join(queries)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m data = response.json()\n\u001b[32m     55\u001b[39m response.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/requests_cache/session.py:127\u001b[39m, in \u001b[36mCacheMixin.get\u001b[39m\u001b[34m(self, url, params, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs) -> AnyResponse:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    126\u001b[39m     kwargs.setdefault(\u001b[33m'\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/requests_cache/session.py:183\u001b[39m, in \u001b[36mCacheMixin.request\u001b[39m\u001b[34m(self, method, url, headers, expire_after, only_if_cached, refresh, force_refresh, *args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m headers = set_request_headers(headers, expire_after, only_if_cached, refresh, force_refresh)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m patch_form_boundary() \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mfiles\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/requests_cache/session.py:230\u001b[39m, in \u001b[36mCacheMixin.send\u001b[39m\u001b[34m(self, request, expire_after, only_if_cached, refresh, force_refresh, **kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._resend(request, actions, cached_response, **kwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m actions.send_request:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_and_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    232\u001b[39m     response = cached_response  \u001b[38;5;66;03m# type: ignore  # Guaranteed to be non-None by this point\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/requests_cache/session.py:254\u001b[39m, in \u001b[36mCacheMixin._send_and_cache\u001b[39m\u001b[34m(self, request, actions, cached_response, **kwargs)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a request and cache the response, unless disabled by settings or headers.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03mIf applicable, also handle conditional requests.\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    253\u001b[39m request = actions.update_request(request)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m actions.update_from_response(response)\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m actions.skip_write:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print('Cultural Dataset argumentation start')\n",
    "factory = CU_Dataset_Factory('.')\n",
    "train_l = Hf_Loader(\"sapienzanlp/nlp2025_hw1_cultural_dataset\", 'train')\n",
    "validation_l = Hf_Loader(\"sapienzanlp/nlp2025_hw1_cultural_dataset\", 'validation')\n",
    "\n",
    "factory.produce(train_l, 'train.tsv', ['languages', 'num_langs', 'reference', 'n_mod', 'back_links'], 'label', 16, False)\n",
    "factory.produce(validation_l, 'validation.tsv', ['languages', 'num_langs', 'reference', 'n_mod', 'back_links'], 'label', 16, False)\n",
    "print('End process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.tsv', sep='\\t')\n",
    "validation = pd.read_csv('validation.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2e549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>back_links</th>\n",
       "      <th>n_mod</th>\n",
       "      <th>G_num_components</th>\n",
       "      <th>G_avg</th>\n",
       "      <th>G_nodes</th>\n",
       "      <th>G_largest_component_size</th>\n",
       "      <th>G_mean_pr</th>\n",
       "      <th>G_density</th>\n",
       "      <th>G_num_cliques</th>\n",
       "      <th>num_langs</th>\n",
       "      <th>reference</th>\n",
       "      <th>languages</th>\n",
       "      <th>type</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "      <th>wiki_name</th>\n",
       "      <th>qid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>entity</td>\n",
       "      <td>film</td>\n",
       "      <td>films</td>\n",
       "      <td>916 (film)</td>\n",
       "      <td>Q32786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.417582</td>\n",
       "      <td>182.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.013903</td>\n",
       "      <td>179.0</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>entity</td>\n",
       "      <td>musical group</td>\n",
       "      <td>music</td>\n",
       "      <td>!!!</td>\n",
       "      <td>Q371</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.244156</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>entity</td>\n",
       "      <td>comics</td>\n",
       "      <td>comics and anime</td>\n",
       "      <td>¡Soborno!</td>\n",
       "      <td>Q3729947</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>227</td>\n",
       "      <td>2375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.455357</td>\n",
       "      <td>224.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>231.0</td>\n",
       "      <td>38</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>entity</td>\n",
       "      <td>musical group</td>\n",
       "      <td>music</td>\n",
       "      <td>+44 (band)</td>\n",
       "      <td>Q158611</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.339623</td>\n",
       "      <td>159.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>entity</td>\n",
       "      <td>building</td>\n",
       "      <td>architecture</td>\n",
       "      <td>1 Monk Street, Monmouth</td>\n",
       "      <td>Q280375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  back_links  n_mod  ...                wiki_name       qid  label\n",
       "0           0          36     79  ...               916 (film)    Q32786      1\n",
       "1           1         222    614  ...                      !!!      Q371      2\n",
       "2           2          24     16  ...                ¡Soborno!  Q3729947      2\n",
       "3           3         227   2375  ...               +44 (band)   Q158611      2\n",
       "4           4          85     30  ...  1 Monk Street, Monmouth   Q280375      1\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f56e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>back_links</th>\n",
       "      <th>n_mod</th>\n",
       "      <th>G_num_components</th>\n",
       "      <th>G_avg</th>\n",
       "      <th>G_nodes</th>\n",
       "      <th>G_largest_component_size</th>\n",
       "      <th>G_mean_pr</th>\n",
       "      <th>G_density</th>\n",
       "      <th>G_num_cliques</th>\n",
       "      <th>num_langs</th>\n",
       "      <th>reference</th>\n",
       "      <th>languages</th>\n",
       "      <th>type</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "      <th>wiki_name</th>\n",
       "      <th>qid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2582</td>\n",
       "      <td>784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.264605</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>entity</td>\n",
       "      <td>sports club</td>\n",
       "      <td>sports</td>\n",
       "      <td>1. FC Nürnberg</td>\n",
       "      <td>Q15786</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>entity</td>\n",
       "      <td>record label</td>\n",
       "      <td>music</td>\n",
       "      <td>77 Records</td>\n",
       "      <td>Q268530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>841</td>\n",
       "      <td>2698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.452888</td>\n",
       "      <td>329.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>343.0</td>\n",
       "      <td>68</td>\n",
       "      <td>166</td>\n",
       "      <td>10</td>\n",
       "      <td>entity</td>\n",
       "      <td>animated film</td>\n",
       "      <td>comics and anime</td>\n",
       "      <td>A Bug's Life</td>\n",
       "      <td>Q216153</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>entity</td>\n",
       "      <td>film</td>\n",
       "      <td>films</td>\n",
       "      <td>A Gang Story</td>\n",
       "      <td>Q593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1940</td>\n",
       "      <td>1653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.436170</td>\n",
       "      <td>188.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.013369</td>\n",
       "      <td>177.0</td>\n",
       "      <td>60</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>entity</td>\n",
       "      <td>choreographer</td>\n",
       "      <td>performing arts</td>\n",
       "      <td>Aaron Copland</td>\n",
       "      <td>Q192185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  back_links  n_mod  ...       wiki_name      qid  label\n",
       "0           0        2582    784  ...  1. FC Nürnberg   Q15786      2\n",
       "1           1          27     25  ...      77 Records  Q268530      1\n",
       "2           2         841   2698  ...    A Bug's Life  Q216153      2\n",
       "3           3          21     36  ...    A Gang Story     Q593      1\n",
       "4           4        1940   1653  ...   Aaron Copland  Q192185      2\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe997e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[['label']]\n",
    "y_validation = validation[['label']]\n",
    "\n",
    "id_train = train[['wiki_name']]\n",
    "id_validation = validation[['wiki_name']]\n",
    "\n",
    "fe_train = train[['languages', 'num_langs', 'reference','G_mean_pr']]\n",
    "fe_validation = validation[['languages', 'num_langs', 'reference','G_mean_pr']]\n",
    "\n",
    "fe_str_train = train[['category', 'subcategory', 'type']]\n",
    "fe_str_validation = validation[['category', 'subcategory', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat, validation_cat, _ =  onehot_encode(fe_str_train, fe_str_validation, ['category'] )\n",
    "train_scat, validation_scat, _ = onehot_encode(fe_str_train, fe_str_validation, ['subcategory'] )\n",
    "train_t, validation_t, _ = onehot_encode(fe_str_train, fe_str_validation, ['type'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34cf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 19)\n",
      "(300, 112)\n",
      "(300, 2)\n"
     ]
    }
   ],
   "source": [
    "print(validation_cat.shape)\n",
    "print(validation_scat.shape)\n",
    "print(validation_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c32db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6251, 138)\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([fe_train, train_cat, train_scat, train_t, y_train], axis=1)\n",
    "validation = pd.concat([fe_validation, validation_cat, validation_scat, validation_t, y_validation], axis=1) \n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a46a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>languages</th>\n",
       "      <th>num_langs</th>\n",
       "      <th>reference</th>\n",
       "      <th>G_mean_pr</th>\n",
       "      <th>category_architecture</th>\n",
       "      <th>category_biology</th>\n",
       "      <th>category_books</th>\n",
       "      <th>category_comics and anime</th>\n",
       "      <th>category_fashion</th>\n",
       "      <th>category_films</th>\n",
       "      <th>category_food</th>\n",
       "      <th>category_geography</th>\n",
       "      <th>category_gestures and habits</th>\n",
       "      <th>category_history</th>\n",
       "      <th>category_literature</th>\n",
       "      <th>category_media</th>\n",
       "      <th>category_music</th>\n",
       "      <th>category_performing arts</th>\n",
       "      <th>category_philosophy and religion</th>\n",
       "      <th>category_politics</th>\n",
       "      <th>category_sports</th>\n",
       "      <th>category_transportation</th>\n",
       "      <th>category_visual arts</th>\n",
       "      <th>subcategory_acting style</th>\n",
       "      <th>subcategory_actor</th>\n",
       "      <th>subcategory_animal</th>\n",
       "      <th>subcategory_animated film</th>\n",
       "      <th>subcategory_animation studio</th>\n",
       "      <th>subcategory_animation technique</th>\n",
       "      <th>subcategory_architect</th>\n",
       "      <th>subcategory_architectural structure</th>\n",
       "      <th>subcategory_architectural style</th>\n",
       "      <th>subcategory_archive</th>\n",
       "      <th>subcategory_art gallery</th>\n",
       "      <th>subcategory_art movement</th>\n",
       "      <th>subcategory_artist</th>\n",
       "      <th>subcategory_athlete</th>\n",
       "      <th>subcategory_automobile manufacturer</th>\n",
       "      <th>subcategory_biologist</th>\n",
       "      <th>subcategory_body language</th>\n",
       "      <th>...</th>\n",
       "      <th>subcategory_philosophical movement</th>\n",
       "      <th>subcategory_philosophy</th>\n",
       "      <th>subcategory_photographer</th>\n",
       "      <th>subcategory_plant</th>\n",
       "      <th>subcategory_poet</th>\n",
       "      <th>subcategory_poetry</th>\n",
       "      <th>subcategory_policy</th>\n",
       "      <th>subcategory_political party</th>\n",
       "      <th>subcategory_politician</th>\n",
       "      <th>subcategory_production company</th>\n",
       "      <th>subcategory_publisher</th>\n",
       "      <th>subcategory_record label</th>\n",
       "      <th>subcategory_recurring sporting event</th>\n",
       "      <th>subcategory_religion</th>\n",
       "      <th>subcategory_religious book</th>\n",
       "      <th>subcategory_religious leader</th>\n",
       "      <th>subcategory_religious movement</th>\n",
       "      <th>subcategory_ritual</th>\n",
       "      <th>subcategory_river</th>\n",
       "      <th>subcategory_sport</th>\n",
       "      <th>subcategory_sports club</th>\n",
       "      <th>subcategory_sports equipment</th>\n",
       "      <th>subcategory_sports team</th>\n",
       "      <th>subcategory_station</th>\n",
       "      <th>subcategory_streaming service</th>\n",
       "      <th>subcategory_television</th>\n",
       "      <th>subcategory_textile</th>\n",
       "      <th>subcategory_theatrical director</th>\n",
       "      <th>subcategory_theatrical genre</th>\n",
       "      <th>subcategory_tradition</th>\n",
       "      <th>subcategory_traditional costume</th>\n",
       "      <th>subcategory_transport</th>\n",
       "      <th>subcategory_transport company</th>\n",
       "      <th>subcategory_tree</th>\n",
       "      <th>subcategory_visual arts</th>\n",
       "      <th>subcategory_writer</th>\n",
       "      <th>subcategory_writing style</th>\n",
       "      <th>type_concept</th>\n",
       "      <th>type_entity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   languages  num_langs  reference  ...  type_concept type_entity label\n",
       "0          2          6          5  ...           0.0         1.0     1\n",
       "1          8         30         40  ...           0.0         1.0     2\n",
       "2          3          4          1  ...           0.0         1.0     2\n",
       "\n",
       "[3 rows x 138 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0b35a",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea974e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44b664",
   "metadata": {},
   "source": [
    "### Agnostic-Representative classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset in order to take only two classes and eliminates the labels of the elements\n",
    "d = train.query(\"label == 0 or label == 1\")\n",
    "y = d['label'].astype(int).to_numpy()\n",
    "x = d.drop(['label'], axis=1).astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/miniconda3/envs/MNLP/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ar_tree = MLPClassifier().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = validation.query(\"label == 0 or label == 1\")\n",
    "y = d['label'].astype(int).to_numpy()\n",
    "x = d.drop(['label'], axis=1).astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeccb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       117\n",
      "           1       0.83      0.88      0.85        76\n",
      "\n",
      "    accuracy                           0.88       193\n",
      "   macro avg       0.87      0.88      0.88       193\n",
      "weighted avg       0.88      0.88      0.88       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ar_tree.predict(x)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db137e02",
   "metadata": {},
   "source": [
    "## Agnostic-Exclusive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset in order to take only two classes and eliminates the labels of the elements\n",
    "d = train.query(\"label == 0 or label == 2\")\n",
    "y = d['label'].astype(int).to_numpy()\n",
    "x = d.drop(['label'], axis=1).astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f024d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/miniconda3/envs/MNLP/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ae_tree = MLPClassifier().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = validation.query(\"label == 0 or label == 2\")\n",
    "y = d['label'].astype(int).to_numpy()\n",
    "x = d.drop(['label'], axis=1).astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       117\n",
      "           2       0.79      0.73      0.76       107\n",
      "\n",
      "    accuracy                           0.78       224\n",
      "   macro avg       0.78      0.77      0.78       224\n",
      "weighted avg       0.78      0.78      0.78       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ae_tree.predict(x)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e660edf4",
   "metadata": {},
   "source": [
    "## Representative-Exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset in order to take only two classes and eliminates the labels of the elements\n",
    "d = train.query(\"label == 1 or label == 2\")\n",
    "y = d['label'].astype(int).to_numpy()\n",
    "x = d.drop(['label'], axis=1).astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbb492",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tree = RandomForestClassifier().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = validation.query(\"label == 1 or label == 2\")\n",
    "y = d['label'].astype(int).to_numpy()\n",
    "x = d.drop(['label'], axis=1).astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204616b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.80      0.74        76\n",
      "           2       0.84      0.75      0.79       107\n",
      "\n",
      "    accuracy                           0.77       183\n",
      "   macro avg       0.77      0.78      0.77       183\n",
      "weighted avg       0.78      0.77      0.77       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = re_tree.predict(x)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255d629",
   "metadata": {},
   "source": [
    "# Voting Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Cultural-classification Network\n",
    "class CABNet(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, ar_estimator, ae_estimator, re_estimator) -> None:\n",
    "        self.ar = ar_estimator \n",
    "        self.ae = ae_estimator \n",
    "        self.re = re_estimator\n",
    "        self.detector = IsolationForest()\n",
    "        \n",
    "    \n",
    "    def __fit(self, e, X, y) -> BaseEstimator:\n",
    "        return e.fit(X, y)\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        outliers = self.detector.fit_predict(X)\n",
    "        print(outliers)\n",
    "\n",
    "        d = X.query(\"label == 0 or label == 1 and @ouliers == 0\")\n",
    "        y = d['label'].astype(int).to_numpy()\n",
    "        x = d.drop(['label'], axis=1).astype(float).to_numpy()\n",
    "        self.ar = self.__fit(self.ar, x, y)\n",
    "        d = X.query(\"label == 0 or label == 2\")\n",
    "        y = d['label'].astype(int).to_numpy()\n",
    "        x = d.drop(['label'], axis=1).astype(float).to_numpy()\n",
    "        self.ae = self.__fit(self.ae, x, y)\n",
    "        d = X.query(\"label == 1 or label == 2\")\n",
    "        y = d['label'].astype(int).to_numpy()\n",
    "        x = d.drop(['label'], axis=1).astype(float).to_numpy()\n",
    "        self.re = self.__fit(self.re, x, y)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        v1 = self.ar.predict(X)\n",
    "        v2 = self.ae.predict(X)\n",
    "        v3 = self.re.predict(X)\n",
    "     \n",
    "  \n",
    "        votes = np.vstack([v1, v2, v3])\n",
    "        majority, _ = mode(votes, axis=0)\n",
    "        return majority.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, IsolationForest\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd526559",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  CABNet(RandomForestClassifier(n_estimators=100), RandomForestClassifier(n_estimators=550), RandomForestClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d654b29",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[471]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[468]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mCABNet.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     46\u001b[39m s3 = \u001b[38;5;28mself\u001b[39m.d3.fit(x_re, y_re).score_samples(x_re)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Training decisor\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m S = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (n_samples, 3)\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mself\u001b[39m.decisor = \u001b[38;5;28mself\u001b[39m.__fit(\u001b[38;5;28mself\u001b[39m.decisor, S, y_re)  \u001b[38;5;66;03m# ATTENZIONE: devi scegliere quale y qui! Ne parliamo sotto\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/numpy/_core/shape_base.py:460\u001b[39m, in \u001b[36mstack\u001b[39m\u001b[34m(arrays, axis, out, dtype, casting)\u001b[39m\n\u001b[32m    458\u001b[39m shapes = {arr.shape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) != \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mall input arrays must have the same shape\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    462\u001b[39m result_ndim = arrays[\u001b[32m0\u001b[39m].ndim + \u001b[32m1\u001b[39m\n\u001b[32m    463\u001b[39m axis = normalize_axis_index(axis, result_ndim)\n",
      "\u001b[31mValueError\u001b[39m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "model = model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = validation\n",
    "y = d['label'].astype(int).to_numpy()\n",
    "x = d.drop(['label'], axis=1).astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a43b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          0.         ...  1.          1.\n",
      "   0.        ]\n",
      " [ 2.          2.          2.         ...  0.          2.\n",
      "   2.        ]\n",
      " [ 1.          1.          2.         ...  1.          2.\n",
      "   1.        ]\n",
      " [-0.34112483 -0.34260664 -0.36596736 ... -0.32239063 -0.33204853\n",
      "  -0.32330366]\n",
      " [-0.36214006 -0.33588173 -0.34261531 ... -0.33643126 -0.32600381\n",
      "  -0.33444503]\n",
      " [-0.36063496 -0.31978196 -0.32804783 ... -0.34991134 -0.33613358\n",
      "  -0.32591378]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[459]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m y_pred = model.predict(x)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2671\u001b[39m, in \u001b[36mclassification_report\u001b[39m\u001b[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[32m   2564\u001b[39m \n\u001b[32m   2565\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2667\u001b[39m \u001b[33;03m<BLANKLINE>\u001b[39;00m\n\u001b[32m   2668\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2670\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m-> \u001b[39m\u001b[32m2671\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2674\u001b[39m     labels = unique_labels(y_true, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/sklearn/metrics/_classification.py:107\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m    104\u001b[39m     y_type = {\u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mClassification metrics can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m targets\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    109\u001b[39m             type_true, type_pred\n\u001b[32m    110\u001b[39m         )\n\u001b[32m    111\u001b[39m     )\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[32m    114\u001b[39m y_type = y_type.pop()\n",
      "\u001b[31mValueError\u001b[39m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x)\n",
    "print(classification_report(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
