{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d33d8a",
   "metadata": {},
   "source": [
    "# Cultural Classification with Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424d5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/miniconda3/envs/MNLP/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import for load dataset \n",
    "from CU_Dataset_Factory import Hf_Loader, Local_Loader, CU_Dataset_Factory\n",
    "# Import Datases for work with Transformers by Hugging-Face\n",
    "from datasets import Dataset\n",
    "from datasets import Features\n",
    "from datasets import Split, Value\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60ae2a3",
   "metadata": {},
   "source": [
    "## Global Notebook Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095a32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b04ccf",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0303aff",
   "metadata": {},
   "source": [
    "Choose appropriate features. Avaiable features are\n",
    "\n",
    "* *'description'* - sintetic Wikidata description for item\n",
    "* *'intro'* - Wikipedia page introduction\n",
    "* *'full_page*' - full Wikipedia plain-text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6bb6985",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = 'description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65edf8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file      = \"train.csv\" #@param {type:\"string\"}\n",
    "validation_file = \"validation.csv\" #@param {type:\"string\"}\n",
    "\n",
    "######################################################\n",
    "# not modify this row for testing    purpose         #\n",
    "test_file       = \"tr_test.tsv\" #@param {type:\"string\"} #\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192117a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = CU_Dataset_Factory(f'./experiment_n{time()}')\n",
    "if is_train:\n",
    "    train_l = Hf_Loader(\"sapienzanlp/nlp2025_hw1_cultural_dataset\", 'train')\n",
    "    validation_l = Hf_Loader(\"sapienzanlp/nlp2025_hw1_cultural_dataset\", 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6dc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    train = factory.produce(train_l, 'tr_train.tsv', [fe], 'label', 45, True, False)\n",
    "    validation  = factory.produce(validation_l, 'tr_validation.tsv', [fe], 'label', 45,True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bd3dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    train_data = train[['label', fe]].rename({fe: 'text'}, axis=1)\n",
    "    validation_data = validation[['label', fe]].rename({fe: 'text'}, axis=1)\n",
    "\n",
    "    # Prepare Dataset for the Model\n",
    "\n",
    "    train_data = Dataset.from_pandas(train_data, features=Features({\n",
    "        'label': Value('int32'),\n",
    "        'text' : Value('string')\n",
    "    }), split=Split.TRAIN)\n",
    "\n",
    "    validation_data = Dataset.from_pandas(validation_data, features=Features({\n",
    "        'label': Value('int32'),\n",
    "        'text' : Value('string')\n",
    "    }), split=Split.VALIDATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fcedb",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "310168c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for Transformers\n",
    "from transformers import AutoTokenizer # Datasets\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification # Model\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import numpy as np # eval\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f906880",
   "metadata": {},
   "source": [
    "### Tested Models\n",
    "We have tested major pretrained model using differente features, foreach we have reported accuracy value\n",
    "* google/mobilebert-uncased ()\n",
    "* microsoft/deberta-v3-xsmall (wiki_desc - 78%)\n",
    "* microsoft/MiniLM-L12-H384-uncased\n",
    "* distilbert/distilbert-base-uncased-distilled-squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c0a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repo = 'distilbert/distilbert-base-uncased-distilled-squad'\n",
    "# my be customize the classification head after import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8bb379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-distilled-squad and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if is_train:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_repo, num_labels=3, ignore_mismatched_sizes=True)\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-uncased-distilled-squad', num_labels=3, ignore_mismatched_sizes=True)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54d2cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, tokenizer) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "    def process_samples(self, samples):\n",
    "        return samples.map(lambda sample: self.tokenizer(sample['text'], truncation=True, max_length=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64092eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = evaluate.load(\"accuracy\")\n",
    "   load_f1 = evaluate.load(\"f1\")\n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels, average='micro')[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddaf6ae",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Tokenize the text ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3493202",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_repo, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c824d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocessor(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcfca7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    tokenize_train = p.process_samples(train_data)\n",
    "    tokenize_validation = p.process_samples(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d67a0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DataCollatorWithPadding(tokenizer, max_length=tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d524a12",
   "metadata": {},
   "source": [
    "## Tran and Evaluate the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063df6b3",
   "metadata": {},
   "source": [
    "### Train (enabled if `is_train` is True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bb6bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "epochs = 1\n",
    "batch_size = 1\n",
    "weight_decay = 0\n",
    "learning_rate = 1e-4\n",
    "out_dir = 'CU_with_DBert'\n",
    "log = 'Cultural Analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1d55959",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls2label = {0:'Cultural Agnostic', 1:'Cultural Rapresentative', 2:'Cultural Exclusive'}\n",
    "label2cls = {l:c for c ,l in cls2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9e7833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_args = TrainingArguments(\n",
    "    output_dir=out_dir,\n",
    "    eval_strategy='epoch',\n",
    "    push_to_hub=False,\n",
    "    num_train_epochs = epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    warmup_steps=0,\n",
    "    weight_decay=weight_decay,\n",
    "    learning_rate=learning_rate,             \n",
    "    report_to=\"none\",\n",
    "    logging_dir=log \n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8abe1a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    trainer = Trainer(model,traning_args, collector, tokenize_train, tokenize_validation,tokenizer,compute_metrics=compute_metrics)\n",
    "    print(f'Model running on {trainer.model.device}')\n",
    "    trainer.train()\n",
    "    report = trainer.evaluate()\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e242e5c7",
   "metadata": {},
   "source": [
    "### Test Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a2e49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "\n",
    "from torch import tensor\n",
    "from torch.nn import Module\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from datasets import Dataset\n",
    "def predict_culture_pd(ds:Dataset, model:Module, tokenizer, device, max_length=128) -> Series:\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    encoding =   ds.map( lambda v: tokenizer(v['text'], return_tensors='pt', max_length=max_length, padding='max_length', truncation=True))\n",
    "    input_ids = tensor( encoding['input_ids'] ).squeeze().to(device)\n",
    "    attention_mask = tensor(encoding['attention_mask']).squeeze().to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "    labels = preds.numpy(force=True)\n",
    "    return Series(labels)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "afabd40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Local_Loader(test_file)\n",
    "test = loader.get()\n",
    "#test = factory.produce(loader, out_file=None, enable_feature=[fe], targe_feature=None, batch_s=45)\n",
    "train_data = test[[fe]].rename({fe: 'text'}, axis=1)\n",
    "train_ds = Dataset.from_pandas(train_data, features=Features({\n",
    "    'text' : Value('string')\n",
    "}), split=Split.TEST)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased-distilled-squad')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe046bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 300/300 [00:00<00:00, 4928.89 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       qid                    wiki_name\n",
      "0   Q15786               1. FC Nürnberg\n",
      "1  Q268530                   77 Records\n",
      "2  Q216153                 A Bug's Life\n",
      "3     Q593                 A Gang Story\n",
      "4  Q192185                Aaron Copland\n",
      "5  Q265890             Aarwangen Castle\n",
      "6  Q305718                        Abaya\n",
      "7  Q337267        Academy of San Carlos\n",
      "8      Q15                       Africa\n",
      "9  Q388170  African-American literature\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_culture_pd(train_ds, model, tokenizer, ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "test.insert(loc=len(test.columns), column='label', value=y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a89ee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       qid                    wiki_name  label\n",
      "0   Q15786               1. FC Nürnberg      1\n",
      "1  Q268530                   77 Records      1\n",
      "2  Q216153                 A Bug's Life      1\n",
      "3     Q593                 A Gang Story      1\n",
      "4  Q192185                Aaron Copland      1\n",
      "5  Q265890             Aarwangen Castle      1\n",
      "6  Q305718                        Abaya      1\n",
      "7  Q337267        Academy of San Carlos      1\n",
      "8      Q15                       Africa      1\n",
      "9  Q388170  African-American literature      1\n"
     ]
    }
   ],
   "source": [
    "print(test[['qid', 'wiki_name','label']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bfb31def",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Save file for evaluation purposes #\n",
    "#####################################\n",
    "\n",
    "test.to_csv('results_TransformersNetwork.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
