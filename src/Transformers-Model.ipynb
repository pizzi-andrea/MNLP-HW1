{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdbb378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424d5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/miniconda3/envs/MNLP/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from CU_Dataset_Factory import Hf_Loader, CU_Dataset_Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192117a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = CU_Dataset_Factory('.')\n",
    "train_l = Hf_Loader(\"sapienzanlp/nlp2025_hw1_cultural_dataset\", 'train')\n",
    "validation_l = Hf_Loader(\"sapienzanlp/nlp2025_hw1_cultural_dataset\", 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8ed8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = 'intro'\n",
    "model_repo = 'google/mobilebert-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6dc6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:01<00:00, 89.57it/s]\n",
      "copy dataset: 100%|██████████| 1/1 [00:00<00:00, 1100.00it/s]\n",
      "intro: 100%|██████████| 6251/6251 [00:01<00:00, 5067.16it/s, batch=196]\n",
      "100%|██████████| 6/6 [00:00<00:00, 289.50it/s]\n",
      "copy dataset: 100%|██████████| 1/1 [00:00<00:00, 1952.66it/s]\n",
      "intro: 100%|██████████| 300/300 [00:00<00:00, 9856.43it/s, batch=10] \n"
     ]
    }
   ],
   "source": [
    "train = factory.produce(train_l, 'tr_train.tsv', [fe], 'label', 32, False)\n",
    "test  = factory.produce(validation_l, 'tr_validation.tsv', [fe], 'label', 32, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd3dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[['label', fe]].rename({fe: 'text'}, axis=1)\n",
    "validation_data = test[['label', fe]].rename({fe: 'text'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c0a1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "intro",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wiki_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "qid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b61b32ac-5926-4f19-bf86-4c6036802c7d",
       "rows": [
        [
         "0",
         "",
         "916 (film)",
         "Q32786",
         "1"
        ],
        [
         "1",
         "!!! ( ch(i)k-ch(i)k-ch(i)k), also known as Chk Chk Chk, is an American band from Sacramento, California. \nFormed in 1996 by lead singer Nic Offer, members of !!! came from other local bands such as the Yah Mos, Black Liquorice and Pope Smashers. They are currently based in New York City. The band's ninth album, Let It Be Blue, was released in May 2022.\n\n",
         "!!!",
         "Q371",
         "2"
        ],
        [
         "2",
         "",
         "¡Soborno!",
         "Q3729947",
         "2"
        ],
        [
         "3",
         "+44 (read as Plus Forty-four) was an American rock supergroup formed in Los Angeles, California, in 2005. The group consisted of vocalist and bassist Mark Hoppus and drummer Travis Barker of Blink-182, lead guitarist Shane Gallagher of the Nervous Return, and rhythm guitarist Craig Fairbaugh of Mercy Killers. Hoppus and Barker created +44 shortly after the initial 2005 breakup of Blink-182 and before it was later reformed. The band's name refers to the international dialing code of the United Kingdom, the country where the duo first discussed the project. Early recordings were largely electronic in nature, and featured vocals by Carol Heller, formerly of the all-girl punk quartet Get the Girl.\nThe band's sound gradually took on a heavier tone as Hoppus and Barker purchased a studio in which to record. Although anticipated by the music press, the band's only album—When Your Heart Stops Beating (2006)—underperformed commercial expectations and received mixed reviews from critics.The group toured worldwide throughout 2006 and 2007, including a summer slot on the Honda Civic Tour alongside Fall Out Boy. Hoppus later began preparing material for a second +44 album, but the group went inactive with the reunion of Blink-182 in 2009.\n\n",
         "+44 (band)",
         "Q158611",
         "2"
        ],
        [
         "4",
         "1 Monk Street, Monmouth was built as a Working Men's Free Institute. It is a Grade II Listed building in Monmouth, Wales and located next to Monmouth Baptist Church.\nThe architect was Benjamin Lawrence of Newport who later designed the church next door. The institute's staircase was made by Macfarlane, Glasgow, Wrought Ironwork was by Cormell Cheltenham and the carvings were by J Willis. The building opened in 1868. A smoking room and lecture room were added in 1897.\n\n",
         "1 Monk Street, Monmouth",
         "Q280375",
         "1"
        ],
        [
         "5",
         "The 100 percent corner is the busiest area in a city. Often it is a crossroads of several major streets, and the place with the highest land value and/or where grid plan numbering is based upon. The term is also used for the place for ideal real estate projects, sometimes considered the intersection of two highways in a suburban area. The terms \"hundred percent location\", \"hundred percent corner\", or \"peak land value intersection\" may also be used.\nThe 100 percent corner is used in research as part of a method to determine a city's downtown area, by measuring a radius (e.g. one mile) from the central intersection.\n\nExamples\nBroad and High Streets in Columbus, Ohio\nFayette Street and South Salina Street in Syracuse, New York\nFourth and Muhammad Ali Boulevard in Louisville, Kentucky\nChurch and Chapel Streets in New Haven, Connecticut\n\n",
         "100 percent corner",
         "Q104414508",
         "0"
        ],
        [
         "6",
         "The 1889 Apia cyclone was a tropical cyclone in the South Pacific Ocean, which swept across Apia, Samoa on March 15, 1889, during the Samoan crisis. The effect on shipping in the harbour was devastating, largely because of what has been described as \"an error of judgement that will forever remain a paradox in human psychology\".\n\n",
         "1889 Apia cyclone",
         "Q3008535",
         "0"
        ],
        [
         "7",
         "18th Abduction is the eighteenth novel in the Women's Murder Club novel series by James Patterson and Maxine Paetro.\n\n",
         "18th Abduction",
         "Q85720601",
         "0"
        ],
        [
         "8",
         "The 20 July plot was a failed attempt to assassinate Adolf Hitler, the chancellor and leader of Nazi Germany, and overthrow the Nazi regime on 20 July 1944. The plotters were part of the German resistance, mainly composed of Wehrmacht officers. The leader of the conspiracy, Claus von Stauffenberg, tried to kill Hitler by detonating an explosive hidden in a briefcase. However, due to the location of the bomb at the time of detonation, the blast only dealt Hitler minor injuries. The planners' subsequent coup attempt also failed and resulted in a purge of the Wehrmacht.\nAs early as 1938, German military officers had plotted to overthrow Hitler, but indecisive leadership and the pace of global events stymied action. Plotters gained a sense of urgency in 1943, after Germany lost the Battle of Stalingrad and Soviet forces began to push towards Germany. Under the leadership of Stauffenberg, plotters tried to assassinate Hitler at least five different times in 1943 and 1944. With the Gestapo closing in on the plotters, a final attempt was organized in July 1944. Stauffenberg personally took a briefcase full of explosives to a conference in the Wolf's Lair. The explosives were armed and placed next to Hitler, but it appears they were moved unwittingly at the last moment behind a table leg by Heinz Brandt, inadvertently saving Hitler's life. When the bomb detonated, it killed Brandt and two others, while the rest of the room's occupants were injured, one of whom, Rudolf Schmundt, later died from his injuries. Hitler's trousers were singed by the blast, and he suffered a perforated eardrum and conjunctivitis, but was otherwise unharmed.\nThe plotters, unaware of their failure, then attempted a coup d'état. A few hours after the blast, the conspiracy used Wehrmacht units to take control of several cities, including Berlin, right after giving them disinformation on the intention of the orders they were given. This part of the coup d'état attempt is referred to by the name \"Operation Valkyrie\", which also has become associated with the entire event. Within hours, the Nazi regime had reasserted its control of Germany. A few members of the conspiracy, including Stauffenberg, were executed by firing squad the same night. In the months after the coup d'état attempt, the Gestapo arrested more than 7,000 people, 4,980 of whom were executed. Roughly 200 conspirators were executed.\nThe apparent aim of the coup d'état attempt was to wrest political control of Germany and its armed forces from the Nazi Party (including the SS) and to make peace with the Western Allies as soon as possible. The details of the conspirators' peace initiatives remain unknown, but they would have included unrealistic demands for the confirmation of Germany's extensive annexations of European territory.\n\n",
         "20 July plot",
         "Q105570",
         "1"
        ],
        [
         "9",
         "20th Century Studios, Inc., formerly 20th Century Fox, is an American film production and distribution company owned by the Walt Disney Studios, the film studios division of the Disney Entertainment business segment of the Walt Disney Company. It is headquartered at the Fox Studio Lot in the Century City area of Los Angeles, which is leased from Fox Corporation. Walt Disney Studios Motion Pictures distributes and markets the films produced by this studio in theatrical markets.\nFor over 80 years, 20th Century has been one of the major American film studios. It was formed in 1935 as Twentieth Century-Fox Film Corporation by the merger of Fox Film Corporation and Twentieth Century Pictures, and one of the original \"Big Five\" among eight majors of Hollywood's Golden Age. In 1985, the studio removed the hyphen in the name (becoming Twentieth Century Fox Film Corporation) after being acquired by Rupert Murdoch's News Corporation, which was renamed 21st Century Fox in 2013 after it spun off its publishing assets. Disney purchased most of 21st Century Fox's assets, which included 20th Century Fox, on March 20, 2019. The studio adopted its current name on January 17, 2020, in order to avoid confusion with Fox Corporation, and subsequently started to use it for the copyright of 20th Century and Searchlight Pictures productions on December 4. 20th Century is currently one of five live-action film studios within the Walt Disney Studios, alongside Walt Disney Pictures, Marvel Studios, Lucasfilm, and its sister speciality unit, Searchlight Pictures. 20th Century also releases animated films produced by its animation division 20th Century Animation.\nThe most commercially successful film franchises from 20th Century Studios include the first six Star Wars films, X-Men, Ice Age, Avatar, and Planet of the Apes. Additionally, the studio's library includes many individual films such as The Sound of Music and Titanic, both of which won the Academy Award for Best Picture and became the highest-grossing films of all time during their initial releases.\n\n",
         "20th Century Studios",
         "Q434841",
         "2"
        ],
        [
         "10",
         "20th-century French philosophy is a strand of contemporary philosophy generally associated with post-World War II French thinkers, although it is directly influenced by previous philosophical movements.\n\n",
         "20th-century French philosophy",
         "Q4630640",
         "2"
        ],
        [
         "11",
         "Twenty-First Century Fox, Inc., which did business as 21st Century Fox, was an American multinational mass media and entertainment conglomerate based in Midtown Manhattan, New York City. It was formed on June 28, 2013, as the legal successor to News Corporation, while the second News Corporation was formed the same day as a spin-off. 21st Century Fox was the legal successor to News Corporation dealing primarily in the film and television industries. It was the United States' fourth-largest media conglomerate by revenue, up until its acquisition by the Walt Disney Company in 2019. The second News Corporation, which is doing business as News Corp, was spun off from the first News Corporation and holds Rupert Murdoch's print interests and other media assets in Australia (both owned by him and his family via a family trust with 39% interest in each). Murdoch was co-executive chairman, while his sons Lachlan Murdoch and James Murdoch were co-executive chairman and CEO, respectively.\n21st Century Fox's assets included the Fox Entertainment Group—owners of the 20th Century Fox film studio (the company's partial namesake), the Fox television network, and a 73% stake in National Geographic Partners—the commercial media arm of the National Geographic Society, among other assets. It also had significant foreign operations, including the prominent Indian television channel operator Star India. The company ranked No. 109 in the 2018 Fortune 500 list of the largest United States corporations by total revenue.\nOn December 14, 2017, The Walt Disney Company agreed to acquire 21st Century Fox for $52.4 billion in stock. After Comcast mounted an all-cash bid of $65 billion, Disney increased their offer to $71.3 billion in cash and stock. Comcast dropped their bid on July 19, 2018 to instead acquire Sky plc, a British media group in which 21CF held a 39% stake in and also planned to fully acquire back in December 2016; Comcast's acquisition closed on November 7, 2018. On July 27, 2018, Disney's offer was approved by shareholders of both companies. The sale covered the majority of 21CF's entertainment assets, including 20th Century Fox, FX Networks, and National Geographic Partners among others; while the sale also included 21CF's regional Fox Sports Networks, Disney was required to sell them within 90 days of the closure of the acquisition to comply with antitrust rulings. The remaining assets, consisting primarily of the Fox and MyNetworkTV networks, and 21CF's local station, news and national sports assets, were spun out into a new company named Fox Corporation, which began trading on March 19, 2019. Disney's acquisition of 21st Century Fox was closed on March 20 of the same year. After that, all of the included 21CF assets were scattered across the divisions of Disney.\n\n",
         "21st Century Fox",
         "Q5476713",
         "2"
        ],
        [
         "12",
         "2600: The Hacker Quarterly is an American seasonal publication of technical information and articles, many of which are written and submitted by the readership, on a variety of subjects including hacking, telephone switching systems, Internet protocols and services, as well as general news concerning the computer underground.\nWith origins in the phone phreaking community and late 20th-century counterculture, 2600 and its associated conference transitioned to coverage of modern hacker culture, and the magazine has become a platform for speaking out against increased digital surveillance and advocacy of personal and digital freedoms.",
         "2600: The Hacker Quarterly",
         "Q219293",
         "2"
        ],
        [
         "13",
         "The 30th Critics' Choice Awards were presented on February 7, 2025, at the Barker Hangar at the Santa Monica Airport in Santa Monica, California, honoring the finest achievements of filmmaking and television programming in 2024. It was originally scheduled to be held on January 12, but was postponed twice due to the series of wildfires in Southern California. The ceremony was broadcast on E! and was made available to stream the next day on Peacock. Chelsea Handler returned as host for the third consecutive year.\nLike in the previous four years, film and television nominations were announced separately. The television nominations were announced on December 5, 2024. The film nominations were announced on December 12, 2024.\nConclave and Wicked led the film nominations with eleven each, followed by Dune: Part Two and Emilia Pérez with ten each. Shōgun led the television nominations with six, followed by Abbott Elementary, The Diplomat, Disclaimer, Hacks, The Penguin and What We Do in the Shadows with four each.\nWith its win, Anora became the first ever film to win the award for Best Picture without winning any other awards.\n\n",
         "30th Critics' Choice Awards",
         "Q131401366",
         "2"
        ],
        [
         "14",
         "33 Whitecross Street is a grade II listed building in Monmouth,  Wales in the area of St James Square. The property was the site of an archaeological excavation in 2009, which found evidence of Neolithic (prehistoric), Roman, and Medieval activity. The following year, archaeological excavation in the square discovered the first evidence of Mesolithic human settlement in Monmouth.\n\n",
         "33 Whitecross Street, Monmouth",
         "Q520959",
         "1"
        ],
        [
         "15",
         "365 Media Group is a now dormant sports media company that once employed over 100 people in Leeds, England and Cape Town, South Africa.\nBetween 2001 and October 2006, the company was known as ukbetting plc and grew through the acquisition of a number of businesses including: ukbetting.com Ltd, PA Sporting Life Ltd, the UK assets of the Sportal and Sports.com, TEAMtalk Media Group plc and Rivals Digital Media Ltd.\nIn January 2007, 365 Media Group was itself acquired by British Sky Broadcasting and the company now operates as a division of Sky Sports. Later that year, in June 2007, the company's totalbet and ukbetting gaming brands were absorbed into Sky Bet, Sky's own betting brand.\nTEAMtalk, PlanetF1, PlanetRugby, Golf365, Cricket365 and Football365 are now part of Planet Sport Publishing's Planet Sport Network.\n365 Media Group ran a network of sports news and content websites, including TEAMtalk, PlanetF1.com, Football365, sportinglife.com and Sportal. The company was also involved in content syndication to other media owners and mobile network operators.\n\n",
         "365 Media Group",
         "Q4635677",
         "0"
        ],
        [
         "16",
         "",
         "3D animation",
         "Q2850042",
         "0"
        ],
        [
         "17",
         "3D films are motion pictures made to give an illusion of three-dimensional solidity, usually with the help of special glasses worn by viewers. They have existed in some form since 1915, but had been largely relegated to a niche in the motion picture industry because of the costly hardware and processes required to produce and display a 3D film, and the lack of a standardized format for all segments of the entertainment business. Nonetheless, 3D films were prominently featured in the 1950s in American cinema and later experienced a worldwide resurgence in the 1980s and 1990s driven by IMAX high-end theaters and Disney-themed venues. 3D films became increasingly successful throughout the 2000s, peaking with the success of 3D presentations of Avatar in December 2009, after which 3D films again decreased in popularity. Certain directors have also taken more experimental approaches to 3D filmmaking, most notably celebrated auteur Jean-Luc Godard in his film Goodbye to Language.\n\n",
         "3D film",
         "Q229390",
         "0"
        ],
        [
         "18",
         "The 48 Hour Film Project is an annual film competition in which teams of filmmakers are assigned a genre, a character, a prop, and a line of dialogue, and have 48 hours to create a short film containing those elements. The competition has been active since 2001. \nIn the weeks after the 48 hours of filmmaking are complete, screenings are held in each city and a winner is chosen to represent that city at Filmapalooza—a festival that features \"best of\" screenings of the winners from each city. Filmapalooza is hosted by a different city each year. The most recent Filmapalooza, in 2024, was held in Lisbon, Portugal.\n\n",
         "48 Hour Film Project",
         "Q2180721",
         "0"
        ],
        [
         "19",
         "4D film is a presentation system combining motion pictures with synchronized physical effects that occur in the theater. Effects simulated in 4D films include motion, vibration, scent, rain, mist, bubbles, fog, smoke, wind, temperature changes, and strobe lights. Seats in 4D venues vibrate and move.\nAs of 2022, 4D films have been exhibited in more than 65 countries. 4D motion pictures are also exhibited in theme parks.\n\n",
         "4D film",
         "Q1060398",
         "0"
        ],
        [
         "20",
         "5-hour Energy (stylized as 5-hour ENERGY) is an American-made \"energy shot\" manufactured by Living Essentials LLC. The company was founded by CEO Manoj Bhargava and launched in 2004.\n\n",
         "5-hour Energy",
         "Q4639659",
         "0"
        ],
        [
         "21",
         "900 North Michigan is a skyscraper in Chicago, Illinois, U.S., completed in 1989. At 871 feet (265 m) tall, it is the eleventh tallest building in Chicago as of 2023 and the 59th-tallest in the United States. It was developed by Urban Retail Properties in 1988 as an upscale sister to Water Tower Place, one block southeast, and was the second vertical mall built along the Magnificent Mile.\nThe building features a large, upscale shopping mall called 900 North Michigan Shops. Bloomingdale's occupies the rear of its wide, six-story atrium, with other luxury shops and restaurants filling the remaining spaces. For this reason, it is commonly referred to as the \"Bloomingdale's Building\". The mall opened with Henri Bendel as a \"junior anchor,\" since closed. The layout of the retail area reflects lessons learned from Water Tower Place; the anchor's placement at the rear draws shoppers through the space and creates leasable space with valuable Michigan Avenue frontage, while the arrangement of escalators in parallel, rather than in zig-zags, directs foot traffic past more shops.\nOffices originally occupied floors 8–28, but floors 21–28 were converted to condo units in 2007, leaving offices on floors 8–20.  The luxurious Four Seasons Hotel occupies the middle floors (30–46) of the tower. Floors 48–66 are part of the 132 East Delaware Residences, these 106 condominiums were part of the original building plan. A large 12-story parking garage, with retail on the ground level and a medical clinic atop, occupies the rear half of the block, facing Rush Street.\nThe exterior of the tower is clad in limestone and green glass which reflects the light. The building has a steel skeleton on which a concrete frame was erected for the upper floors. Because the building materials changed, cranes used to work on the lower floors could not be used for the concrete portion and new cranes had to be erected to complete the building. Four lit \"lanterns\" atop the structure give it a distinctive skyline presence. They change colors for the Christmas season.\n\n",
         "900 North Michigan",
         "Q275936",
         "1"
        ],
        [
         "22",
         "",
         "Lowlands (festival)",
         "Q1758841",
         "1"
        ],
        [
         "23",
         "",
         "A La Vieille Russie",
         "Q3602929",
         "2"
        ],
        [
         "24",
         "",
         "¡A las armas!",
         "Q3728308",
         "1"
        ],
        [
         "25",
         "",
         "A Lotus for Miss Quon",
         "Q85739206",
         "1"
        ],
        [
         "26",
         "",
         "A Modern Olympia",
         "Q614986",
         "2"
        ],
        [
         "27",
         "",
         "A Young Tiger Playing with Its Mother",
         "Q23912",
         "2"
        ],
        [
         "28",
         "",
         "A-1 Pictures",
         "Q277763",
         "2"
        ],
        [
         "29",
         "",
         "A. P. J. Abdul Kalam",
         "Q9513",
         "2"
        ],
        [
         "30",
         "",
         "AS Roma (Superleague Formula team)",
         "Q1945630",
         "2"
        ],
        [
         "31",
         "",
         "Aardman Animations",
         "Q301092",
         "2"
        ],
        [
         "32",
         "Aba I (or, with his Syriac honorific, Mar Aba I) or Mar Abba the Great was the Patriarch of the Church of the East at Seleucia-Ctesiphon from 540 to 552. He introduced to the church the anaphoras of Theodore of Mopsuestia and Nestorius beside the more ancient liturgical rite of Addai and Mari. Though his tenure as catholicos saw Christians in the region threatened during the Persian-Roman wars and attempts by both Sassanid Persian and Byzantine rulers to interfere with the governance of the church, his reign is reckoned a period of consolidation, and a synod he held in 544 as (despite excluding the Diocese of Merv) instrumental in unifying and strengthening the church. In 544, the Synod of Mar Aba I adopted the ordinances of the Council of Chalcedon. He is thought to have written and translated a number of religious works. After his death in February 552, the faithful carried his casket from his simple home across the Tigris to the monastery of Mar Pithyon.\nAba is a highly regarded and significantly venerated saint in the Assyrian Church of the East, the Ancient Church of the East, and the Chaldean Catholic Church. He is documented in the Ausgewählte Akten Persischer Märtyrer, and The Lesser Eastern Churches, two biographies of Eastern saints. The first seminary of the Chaldean Catholic Church outside of Iraq was established in July 2008 in El Cajon, San Diego, as the Seminary of Mar Abba the Great.\n\n",
         "Aba I",
         "Q2708661",
         "1"
        ],
        [
         "33",
         "Abu ʿAmr ʿAbbad II al-Muʿtadid (Arabic: المعتضد بالله أبو عمرو عبَّاد; died 28 February 1069), a member of the Abbadid dynasty, was  the second independent emir of Seville (reigned 1042–1069) in Al-Andalus. His father, Abu al-Qasim Muhammad ibn Abbad, had established the Taifa of Seville, and Abbad became its emir when Abu al-Qasim died in 1042. He initially had amicable relations with his neighbour Ferdinand I, Count of Castile and King of León, and tolerated the Christian faith in his own lands. Among other acts of friendship, he authorized the transfer of Saint Isidore's relics from Seville to the Basilica of San Isidoro in León.\nAl-Muʿtadid expanded his territory by conquering numerous Islamic taifas (independent principalities), including those of Mértola (1044–45), Huelva (1051), Algeciras (1055), Ronda (1065) and Arcos (1069). In 1053, he invited a number of minor Berber princes from the south to his palace in Seville, suffocating them to death by treating them to an open steam bath, having first sealed up all of the openings in the bathhouse. He also fought against the Zirids of Granada and the Aftasids of Badajoz, but with no conclusive results. In 1063, when Ferdinand I appeared with an army on the outskirts of Seville, Al-Muʿtadid was forced to acknowledge his suzerainty and to pay him tribute.\nAl-Muʿtadid died in 1069 and was succeeded by his son, al-Mu'tamid ibn Abbad.\n\n",
         "Abbad II al-Mu'tadid",
         "Q30556",
         "1"
        ],
        [
         "34",
         "Abbas Kiarostami (Persian: عباس کیارستمی [ʔæbˌbɒːs kijɒːɾostæˈmi] ; 22 June 1940 – 4 July 2016) was an Iranian film director, screenwriter, poet, photographer, and film producer. An active filmmaker from 1970, Kiarostami had been involved in the production of over forty films, including shorts and documentaries. Kiarostami attained critical acclaim for directing the Koker trilogy (1987–1994), Close-Up (1990), The Wind Will Carry Us (1999), and Taste of Cherry (1997), which was awarded the Palme d'Or at the Cannes Film Festival that year. In later works, Certified Copy (2010) and Like Someone in Love (2012), he filmed for the first time outside Iran: in Italy and Japan, respectively. His films Where Is the Friend's House? (1987), Close-Up, and The Wind Will Carry Us were ranked among the 100 best foreign films in a 2018 critics' poll by BBC Culture. Close-Up was also ranked one of the 50 greatest movies of all time in the famous decennial Sight & Sound poll conducted in 2012.\nKiarostami had worked extensively as a screenwriter, film editor, art director, and producer and had designed credit titles and publicity material. He was also a poet, photographer, painter, illustrator, and graphic designer. He was part of a generation of filmmakers in the Iranian New Wave, a Persian cinema movement that started in the late 1960s and emphasized the use of poetic dialogue and allegorical storytelling dealing with political and philosophical issues.\nKiarostami had a reputation for using child protagonists, for documentary-style narrative films, for stories that take place in rural villages, and for conversations that unfold inside cars, using stationary mounted cameras. He is also known for his use of Persian poetry in the dialogue, titles, and themes of his films. Kiarostami's films contain a notable degree of ambiguity, an unusual mixture of simplicity and complexity, and often a mix of fictional and documentary elements. The concepts of change and continuity, in addition to the themes of life and death, play a major role in Kiarostami's works.\n\n",
         "Abbas Kiarostami",
         "Q55210",
         "2"
        ],
        [
         "35",
         "",
         "Lorsch Abbey",
         "Q157550",
         "2"
        ],
        [
         "36",
         "ABC Motors Limited (\"All British (Engine) Company\") of Hersham, Surrey, England was a manufacturer of cars, aircraft, motor scooters, and engines for road and air. Established by Ronald Charteris in Hersham, Surrey in 1912, its chief designer was the young and talented Granville Bradshaw. It was absorbed into Vickers in 1951 and the factory finally closed in the 1970s. Last occupied by Ian Allan Publishing as Hersham's Riverdene Industrial Estate, the factory was demolished around 2017-2018 and redeveloped as a Lidl supermarket (opened February 2019) with flats above.\n\n",
         "ABC Motors",
         "Q262737",
         "0"
        ],
        [
         "37",
         "Abeiku Crentsil is a Ghanaian politician and member of the Eighth Parliament of the Fourth Republic of Ghana representing the Ekumfi Constituency in the Central Region of Ghana on the ticket of the National Democratic Congress.\n\n",
         "Abeiku Crentsil",
         "Q84044419",
         "1"
        ],
        [
         "38",
         "Abid Surti or Aabid Surti (born 5 May 1935) is an Indian painter, author, cartoonist, journalist, environmentalist, playwright and screenwriter. He was given a National Award by the government of India in 1993 for writing a series of short stories called the \"Teesri Aankh\".\n\n",
         "Abid Surti",
         "Q9457",
         "1"
        ],
        [
         "39",
         "",
         "Fir",
         "Q25350",
         "0"
        ],
        [
         "40",
         "The Abitibi River is a river in northeastern Ontario, Canada, which flows northwest from Lake Abitibi to join the Moose River which empties into James Bay. This river is 540 kilometres (340 mi) long, and descends 265 metres (869 ft). It is the ninth longest river in Ontario, Behind the Ottawa River (1,271km), St. Lawrence River (1.197km), Severn River (982km), Albany River (982km), Winnipeg River (813km), Attawapiskat River (748km), English River (615km) and Moose River(547km).\nAbitibi is an Algonquin word meaning \"halfway water\", derived from abitah, which may be translated as \"middle\" or \"halfway\", and nipi, \"water\".  Originally used by the French to designate a band of Algonquin Indians who lived near the lake, the name was descriptive of their location halfway between the trading posts on the Hudson Bay and those on the Ottawa River.\nThe river was an important fur trading route for the Hudson's Bay Company. From 1914 Until 2014, pulp and paper, centered on the town of Iroquois Falls, was an important industry in the heavily forested region through which it flows. The region also supports tourism and gold mining.\nThe Abitibi Canyon Generating Station is located on the river at Abitibi Canyon. The experience of surveying the river for the purposes of building this plant was the inspiration for folk singer Wade Hemsworth's \"The Black Fly Song\".\n\n",
         "Abitibi River",
         "Q59647",
         "1"
        ],
        [
         "41",
         "The Aboriginal and Torres Strait Islander Commission (ATSIC) (1990–2005) was the Australian Government body through which Aboriginal Australians and Torres Strait Islanders were formally involved in the processes of government affecting their lives, established under the Hawke government in 1990. A number of Indigenous programs and organisations fell under the overall umbrella of ATSIC.\nThe agency was dissolved in 2005 in the aftermath of litigation involving its chairperson, Geoff Clark.  It was the longest running Indigenous affairs department to have existed.\n\n",
         "Aboriginal and Torres Strait Islander Commission",
         "Q322956",
         "1"
        ],
        [
         "42",
         "Abraham Lincoln ( LINK-ən; February 12, 1809 – April 15, 1865) was the 16th president of the United States, serving from 1861 until his assassination in 1865. He led the United States through the American Civil War, defeating the Confederate States of America, playing a major role in the abolition of slavery, expanding the power of the federal government, and modernizing the U.S. economy.\nLincoln was born into poverty in a log cabin in Kentucky, and was raised on the frontier. He was self-educated and became a lawyer, Whig Party leader, Illinois state legislator, and U.S. representative. Angered by the Kansas–Nebraska Act of 1854, which opened the territories to slavery, he became a leader of the new Republican Party. He reached a national audience in the 1858 Senate campaign debates against Stephen A. Douglas. Lincoln ran for president in 1860, sweeping the North to gain victory. Pro-slavery elements in the South viewed his election as a threat to slavery, and Southern states began seceding from the nation. They formed the Confederate States of America, which began seizing federal military bases in the South. A little over one month after Lincoln assumed the presidency, Confederate forces attacked Fort Sumter, a U.S. fort in South Carolina. Following the bombardment, Lincoln mobilized forces to suppress the rebellion and restore the union.\nLincoln, a moderate Republican, had to navigate a contentious array of factions with friends and opponents from both the Democratic and Republican parties. His allies, the War Democrats and the Radical Republicans, demanded harsh treatment of the Southern Confederates. He managed the factions by exploiting their mutual enmity, carefully distributing political patronage, and by appealing to the American people. Anti-war Democrats (called \"Copperheads\") despised Lincoln, and some irreconcilable pro-Confederate elements went so far as to plot his assassination. Lincoln unsuccessfully attempted to persuade the border states to agree to compensated emancipation. He suspended the writ of habeas corpus in April 1861, leading to Chief Justice Roger Taney's opinion in Ex parte Merryman, and he averted war with Britain by defusing the Trent Affair. On January 1, 1863, he issued the Emancipation Proclamation, which declared the slaves in the states \"in rebellion\" to be free. It also directed the Army and Navy to \"recognize and maintain the freedom of said persons\" and to receive them \"into the armed service of the United States.\" On November 19, 1863, he delivered the Gettysburg Address, which became one of the most famous speeches in American history. Lincoln closely supervised the strategy and tactics in the war effort, including the selection of generals, and implemented a naval blockade of Southern ports. He promoted the Thirteenth Amendment to the U.S. Constitution, which, in December 1865, abolished slavery, except as punishment for a crime. Lincoln managed his own successful 1864 re-election campaign. He sought to heal the war-torn nation through reconciliation, calling for \"malice toward none; with charity for all\" in his second inaugural address. On April 14, 1865, just five days after the Confederate surrender at Appomattox, he was attending a play at Ford's Theatre in Washington, D.C., with his wife Mary, when he was fatally shot by Confederate sympathizer John Wilkes Booth.\n\nLincoln is remembered as a martyr and a national hero for his wartime leadership and for his efforts to preserve the Union and abolish slavery. He is often ranked in both popular and scholarly polls as the greatest president in American history.\n\n",
         "Abraham Lincoln",
         "Q91",
         "2"
        ],
        [
         "43",
         "ABS-CBN News and Current Affairs, known on-air as ABS-CBN News (formerly known as ABS-CBN News and Public Affairs), is the news and current affairs division of the Philippine media conglomerate ABS-CBN Corporation. The division is the country's largest international news gathering and broadcast organization, maintaining several foreign news bureaus and offices through ABS-CBN's Global division.\nThe division generates news output for the company's media assets such as radio station DWPM Radyo 630 (formerly DZMM Radyo Patrol 630); the former main ABS-CBN terrestrial television network (including its former free-to-air television and radio stations) and its current ad-interim replacements Kapamilya Channel, A2Z, All TV and PRTV Prime Media; cable television through ANC and TeleRadyo Serbisyo (formerly (DZMM) TeleRadyo); international channel TFC; and news websites news.abs-cbn.com and patrol.ph, which the former ranks as the top news website in the country as of November 2021.\n\n",
         "ABS-CBN News and Current Affairs",
         "Q4650387",
         "1"
        ],
        [
         "44",
         "Absolution of the dead is a prayer for or a declaration of absolution of a dead person's sins that takes place at the person's religious funeral.\nSuch prayers are found in the funeral rites of the Catholic Church, Anglicanism, and the Eastern Orthodox Church.\nLiturgists analysing the Roman Rite funeral texts have applied the term \"absolution\" (not \"absolution of the dead\") to the series of chants and prayers that follow Requiem Mass and precede the solemn removal of the body from the church for burial. They have not applied the same term (which does not appear in the official Latin-language liturgical books of the Catholic Church) to the chants and prayers preceding the Mass, in spite of the presence among them of the prayer: \"Absolve, we beseech thee, O Lord, the soul of thy servant from every bond of sin, that he may live again among thy saints and elect in the glory of the resurrection.\"\nIn the early 20th century, the French term absoute was sometimes used instead of \"absolution\".\n\n",
         "Absolution of the dead",
         "Q2822053",
         "1"
        ],
        [
         "45",
         "",
         "Abstract animation",
         "Q332564",
         "0"
        ],
        [
         "46",
         "The Abu Dhabi Grand Prix (Arabic: سباق جائزة أبوظبي الكبرى) is a Formula One motor racing event. The first race took place on 1 November 2009, held at the Hermann Tilke-designed Yas Marina Circuit on Yas Island, near Abu Dhabi, the capital of the United Arab Emirates.\nThe W Abu Dhabi - Yas Island is over the short strait between turn 13 and 14. It was announced in early 2007 at the Abu Dhabi F1 Festival. On 25 June 2008, the FIA announced the provisional 2009 Formula One calendar including the Abu Dhabi Grand Prix as the 19th and final race of the season on 15 November. On 5 November 2008, however, it was announced that the race would be held as the season finale on 1 November, two weeks before the initially planned date, as the 17th and final race. The event has been held every year since, and is due to take place at the Yas Marina Circuit until at least 2030.\nThe inaugural race was Formula One's first day–night race, starting at 17:00 local time. Floodlights used to illuminate the circuit were switched on from the start of the event to ensure a seamless transition from daylight to darkness. Subsequent Abu Dhabi Grands Prix have also been day–night races.\n\n",
         "Abu Dhabi Grand Prix",
         "Q7849",
         "2"
        ],
        [
         "47",
         "Abu Nuwas (أبو نواس, Abū Nuwās) (756-8 – c. 814) was a classical Arabic poet, and the foremost representative of the modern (muhdath) poetry that developed during the first years of the Abbasid Caliphate. He also entered the folkloric tradition, appearing several times in One Thousand and One Nights.\nOf mixed Arab and Persian heritage, he studied in Basra and al-Kufah, first under the poet Walibah ibn al-Hubab, and later under Khalaf al-Ahmar. He also studied the Qur'an, Hadith, and grammar. He earned the favour of the Abbasid caliphs Harun ar-Rashid and al-Amin. He is best known for his wine poetry, and Diwan, his collected volume of poetry that explored religion, pleasure, and homoeroticism.\n\n",
         "Abu Nuwas",
         "Q5670",
         "2"
        ],
        [
         "48",
         "",
         "Al-Shadhili",
         "Q2704613",
         "1"
        ],
        [
         "49",
         "Académico Futebol Clube, or more commonly known as Académico do Porto, was a Portuguese football club from Paranhos, Porto. The club was founded on 15 September 1911. Académico was one of the eight teams taking part in the first Primeira Liga season, the main division in the Portuguese football league system, in the 1934–35 season. They went to play in the league an additional four times. Later Académico lost its ground and ended the professional football team.\nInstead of favouring the return of the football team, they invested in other sports, namely in basketball, roller hockey and team handball, a policy that still remains. As a sports club, Académico has won over one hundred different trophies in the respective sports it competes in.",
         "Académico F.C.",
         "Q337429",
         "1"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 50
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intro</th>\n",
       "      <th>wiki_name</th>\n",
       "      <th>qid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>916 (film)</td>\n",
       "      <td>Q32786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!! ( ch(i)k-ch(i)k-ch(i)k), also known as Chk...</td>\n",
       "      <td>!!!</td>\n",
       "      <td>Q371</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>¡Soborno!</td>\n",
       "      <td>Q3729947</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+44 (read as Plus Forty-four) was an American ...</td>\n",
       "      <td>+44 (band)</td>\n",
       "      <td>Q158611</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 Monk Street, Monmouth was built as a Working...</td>\n",
       "      <td>1 Monk Street, Monmouth</td>\n",
       "      <td>Q280375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The 100 percent corner is the busiest area in ...</td>\n",
       "      <td>100 percent corner</td>\n",
       "      <td>Q104414508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The 1889 Apia cyclone was a tropical cyclone i...</td>\n",
       "      <td>1889 Apia cyclone</td>\n",
       "      <td>Q3008535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18th Abduction is the eighteenth novel in the ...</td>\n",
       "      <td>18th Abduction</td>\n",
       "      <td>Q85720601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The 20 July plot was a failed attempt to assas...</td>\n",
       "      <td>20 July plot</td>\n",
       "      <td>Q105570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20th Century Studios, Inc., formerly 20th Cent...</td>\n",
       "      <td>20th Century Studios</td>\n",
       "      <td>Q434841</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20th-century French philosophy is a strand of ...</td>\n",
       "      <td>20th-century French philosophy</td>\n",
       "      <td>Q4630640</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Twenty-First Century Fox, Inc., which did busi...</td>\n",
       "      <td>21st Century Fox</td>\n",
       "      <td>Q5476713</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2600: The Hacker Quarterly is an American seas...</td>\n",
       "      <td>2600: The Hacker Quarterly</td>\n",
       "      <td>Q219293</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The 30th Critics' Choice Awards were presented...</td>\n",
       "      <td>30th Critics' Choice Awards</td>\n",
       "      <td>Q131401366</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33 Whitecross Street is a grade II listed buil...</td>\n",
       "      <td>33 Whitecross Street, Monmouth</td>\n",
       "      <td>Q520959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>365 Media Group is a now dormant sports media ...</td>\n",
       "      <td>365 Media Group</td>\n",
       "      <td>Q4635677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>3D animation</td>\n",
       "      <td>Q2850042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3D films are motion pictures made to give an i...</td>\n",
       "      <td>3D film</td>\n",
       "      <td>Q229390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The 48 Hour Film Project is an annual film com...</td>\n",
       "      <td>48 Hour Film Project</td>\n",
       "      <td>Q2180721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4D film is a presentation system combining mot...</td>\n",
       "      <td>4D film</td>\n",
       "      <td>Q1060398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5-hour Energy (stylized as 5-hour ENERGY) is a...</td>\n",
       "      <td>5-hour Energy</td>\n",
       "      <td>Q4639659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>900 North Michigan is a skyscraper in Chicago,...</td>\n",
       "      <td>900 North Michigan</td>\n",
       "      <td>Q275936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>Lowlands (festival)</td>\n",
       "      <td>Q1758841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>A La Vieille Russie</td>\n",
       "      <td>Q3602929</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>¡A las armas!</td>\n",
       "      <td>Q3728308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>A Lotus for Miss Quon</td>\n",
       "      <td>Q85739206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>A Modern Olympia</td>\n",
       "      <td>Q614986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>A Young Tiger Playing with Its Mother</td>\n",
       "      <td>Q23912</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>A-1 Pictures</td>\n",
       "      <td>Q277763</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>A. P. J. Abdul Kalam</td>\n",
       "      <td>Q9513</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>AS Roma (Superleague Formula team)</td>\n",
       "      <td>Q1945630</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>Aardman Animations</td>\n",
       "      <td>Q301092</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Aba I (or, with his Syriac honorific, Mar Aba ...</td>\n",
       "      <td>Aba I</td>\n",
       "      <td>Q2708661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Abu ʿAmr ʿAbbad II al-Muʿtadid (Arabic: المعتض...</td>\n",
       "      <td>Abbad II al-Mu'tadid</td>\n",
       "      <td>Q30556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Abbas Kiarostami (Persian: عباس کیارستمی [ʔæbˌ...</td>\n",
       "      <td>Abbas Kiarostami</td>\n",
       "      <td>Q55210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td></td>\n",
       "      <td>Lorsch Abbey</td>\n",
       "      <td>Q157550</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ABC Motors Limited (\"All British (Engine) Comp...</td>\n",
       "      <td>ABC Motors</td>\n",
       "      <td>Q262737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Abeiku Crentsil is a Ghanaian politician and m...</td>\n",
       "      <td>Abeiku Crentsil</td>\n",
       "      <td>Q84044419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Abid Surti or Aabid Surti (born 5 May 1935) is...</td>\n",
       "      <td>Abid Surti</td>\n",
       "      <td>Q9457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td></td>\n",
       "      <td>Fir</td>\n",
       "      <td>Q25350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Abitibi River is a river in northeastern O...</td>\n",
       "      <td>Abitibi River</td>\n",
       "      <td>Q59647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The Aboriginal and Torres Strait Islander Comm...</td>\n",
       "      <td>Aboriginal and Torres Strait Islander Commission</td>\n",
       "      <td>Q322956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Abraham Lincoln ( LINK-ən; February 12, 1809 –...</td>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>Q91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ABS-CBN News and Current Affairs, known on-air...</td>\n",
       "      <td>ABS-CBN News and Current Affairs</td>\n",
       "      <td>Q4650387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Absolution of the dead is a prayer for or a de...</td>\n",
       "      <td>Absolution of the dead</td>\n",
       "      <td>Q2822053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td></td>\n",
       "      <td>Abstract animation</td>\n",
       "      <td>Q332564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The Abu Dhabi Grand Prix (Arabic: سباق جائزة أ...</td>\n",
       "      <td>Abu Dhabi Grand Prix</td>\n",
       "      <td>Q7849</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Abu Nuwas (أبو نواس, Abū Nuwās) (756-8 – c. 81...</td>\n",
       "      <td>Abu Nuwas</td>\n",
       "      <td>Q5670</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td></td>\n",
       "      <td>Al-Shadhili</td>\n",
       "      <td>Q2704613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Académico Futebol Clube, or more commonly know...</td>\n",
       "      <td>Académico F.C.</td>\n",
       "      <td>Q337429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                intro  \\\n",
       "0                                                       \n",
       "1   !!! ( ch(i)k-ch(i)k-ch(i)k), also known as Chk...   \n",
       "2                                                       \n",
       "3   +44 (read as Plus Forty-four) was an American ...   \n",
       "4   1 Monk Street, Monmouth was built as a Working...   \n",
       "5   The 100 percent corner is the busiest area in ...   \n",
       "6   The 1889 Apia cyclone was a tropical cyclone i...   \n",
       "7   18th Abduction is the eighteenth novel in the ...   \n",
       "8   The 20 July plot was a failed attempt to assas...   \n",
       "9   20th Century Studios, Inc., formerly 20th Cent...   \n",
       "10  20th-century French philosophy is a strand of ...   \n",
       "11  Twenty-First Century Fox, Inc., which did busi...   \n",
       "12  2600: The Hacker Quarterly is an American seas...   \n",
       "13  The 30th Critics' Choice Awards were presented...   \n",
       "14  33 Whitecross Street is a grade II listed buil...   \n",
       "15  365 Media Group is a now dormant sports media ...   \n",
       "16                                                      \n",
       "17  3D films are motion pictures made to give an i...   \n",
       "18  The 48 Hour Film Project is an annual film com...   \n",
       "19  4D film is a presentation system combining mot...   \n",
       "20  5-hour Energy (stylized as 5-hour ENERGY) is a...   \n",
       "21  900 North Michigan is a skyscraper in Chicago,...   \n",
       "22                                                      \n",
       "23                                                      \n",
       "24                                                      \n",
       "25                                                      \n",
       "26                                                      \n",
       "27                                                      \n",
       "28                                                      \n",
       "29                                                      \n",
       "30                                                      \n",
       "31                                                      \n",
       "32  Aba I (or, with his Syriac honorific, Mar Aba ...   \n",
       "33  Abu ʿAmr ʿAbbad II al-Muʿtadid (Arabic: المعتض...   \n",
       "34  Abbas Kiarostami (Persian: عباس کیارستمی [ʔæbˌ...   \n",
       "35                                                      \n",
       "36  ABC Motors Limited (\"All British (Engine) Comp...   \n",
       "37  Abeiku Crentsil is a Ghanaian politician and m...   \n",
       "38  Abid Surti or Aabid Surti (born 5 May 1935) is...   \n",
       "39                                                      \n",
       "40  The Abitibi River is a river in northeastern O...   \n",
       "41  The Aboriginal and Torres Strait Islander Comm...   \n",
       "42  Abraham Lincoln ( LINK-ən; February 12, 1809 –...   \n",
       "43  ABS-CBN News and Current Affairs, known on-air...   \n",
       "44  Absolution of the dead is a prayer for or a de...   \n",
       "45                                                      \n",
       "46  The Abu Dhabi Grand Prix (Arabic: سباق جائزة أ...   \n",
       "47  Abu Nuwas (أبو نواس, Abū Nuwās) (756-8 – c. 81...   \n",
       "48                                                      \n",
       "49  Académico Futebol Clube, or more commonly know...   \n",
       "\n",
       "                                           wiki_name         qid  label  \n",
       "0                                         916 (film)      Q32786      1  \n",
       "1                                                !!!        Q371      2  \n",
       "2                                          ¡Soborno!    Q3729947      2  \n",
       "3                                         +44 (band)     Q158611      2  \n",
       "4                            1 Monk Street, Monmouth     Q280375      1  \n",
       "5                                 100 percent corner  Q104414508      0  \n",
       "6                                  1889 Apia cyclone    Q3008535      0  \n",
       "7                                     18th Abduction   Q85720601      0  \n",
       "8                                       20 July plot     Q105570      1  \n",
       "9                               20th Century Studios     Q434841      2  \n",
       "10                    20th-century French philosophy    Q4630640      2  \n",
       "11                                  21st Century Fox    Q5476713      2  \n",
       "12                        2600: The Hacker Quarterly     Q219293      2  \n",
       "13                       30th Critics' Choice Awards  Q131401366      2  \n",
       "14                    33 Whitecross Street, Monmouth     Q520959      1  \n",
       "15                                   365 Media Group    Q4635677      0  \n",
       "16                                      3D animation    Q2850042      0  \n",
       "17                                           3D film     Q229390      0  \n",
       "18                              48 Hour Film Project    Q2180721      0  \n",
       "19                                           4D film    Q1060398      0  \n",
       "20                                     5-hour Energy    Q4639659      0  \n",
       "21                                900 North Michigan     Q275936      1  \n",
       "22                               Lowlands (festival)    Q1758841      1  \n",
       "23                               A La Vieille Russie    Q3602929      2  \n",
       "24                                     ¡A las armas!    Q3728308      1  \n",
       "25                             A Lotus for Miss Quon   Q85739206      1  \n",
       "26                                  A Modern Olympia     Q614986      2  \n",
       "27             A Young Tiger Playing with Its Mother      Q23912      2  \n",
       "28                                      A-1 Pictures     Q277763      2  \n",
       "29                              A. P. J. Abdul Kalam       Q9513      2  \n",
       "30                AS Roma (Superleague Formula team)    Q1945630      2  \n",
       "31                                Aardman Animations     Q301092      2  \n",
       "32                                             Aba I    Q2708661      1  \n",
       "33                              Abbad II al-Mu'tadid      Q30556      1  \n",
       "34                                  Abbas Kiarostami      Q55210      2  \n",
       "35                                      Lorsch Abbey     Q157550      2  \n",
       "36                                        ABC Motors     Q262737      0  \n",
       "37                                   Abeiku Crentsil   Q84044419      1  \n",
       "38                                        Abid Surti       Q9457      1  \n",
       "39                                               Fir      Q25350      0  \n",
       "40                                     Abitibi River      Q59647      1  \n",
       "41  Aboriginal and Torres Strait Islander Commission     Q322956      1  \n",
       "42                                   Abraham Lincoln         Q91      2  \n",
       "43                  ABS-CBN News and Current Affairs    Q4650387      1  \n",
       "44                            Absolution of the dead    Q2822053      1  \n",
       "45                                Abstract animation     Q332564      0  \n",
       "46                              Abu Dhabi Grand Prix       Q7849      2  \n",
       "47                                         Abu Nuwas       Q5670      2  \n",
       "48                                       Al-Shadhili    Q2704613      1  \n",
       "49                                    Académico F.C.     Q337429      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704f246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import Features\n",
    "from datasets import Split, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ff0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_data, features=Features({\n",
    "    'label': Value('int32'),\n",
    "    'text' : Value('string')\n",
    "}), split=Split.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63aaf92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = Dataset.from_pandas(validation_data, features=Features({\n",
    "    'label': Value('int32'),\n",
    "    'text' : Value('string')\n",
    "}), split=Split.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "310168c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3493202",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google/mobilebert-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54d2cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, tokenizer) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "    def process_samples(self, samples):\n",
    "        return samples.map(lambda sample: self.tokenizer(sample['text'], truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c824d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocessor(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcfca7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/6251 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 6251/6251 [00:01<00:00, 3709.56 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 2919.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenize_train = p.process_samples(train_data)\n",
    "tokenize_test = p.process_samples(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd0ae0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d67a0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e831039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64092eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    acc = evaluate.load('accuracy')\n",
    "    \n",
    "    \n",
    "    pred, true = eval_pred\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    return acc.compute(predictions=pred, references=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1d55959",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls2label = {0:'Cultural Agnostic', 1:'Cultural Rapresentative', 2:'Cultural Exclusive'}\n",
    "label2cls = {l:c for c ,l in cls2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10827cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8bb379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = model = AutoModelForSequenceClassification.from_pretrained(model_repo, num_labels=3, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9e7833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_args = TrainingArguments(\n",
    "    output_dir='CU_with_bert',\n",
    "    eval_strategy='epoch',\n",
    "    push_to_hub=False,\n",
    "    num_train_epochs = 10,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=traning_args,\n",
    "    data_collator=collector,\n",
    "    train_dataset=tokenize_train,\n",
    "    eval_dataset=tokenize_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0a8200b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78808776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpizzi-1995517\u001b[0m (\u001b[33mpizzi-1995517-sapienza-universit-di-roma\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/andrea/Documenti/MNLP-HW1/src/wandb/run-20250427_160048-7afa9mn3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pizzi-1995517-sapienza-universit-di-roma/huggingface/runs/7afa9mn3' target=\"_blank\">CU_with_bert</a></strong> to <a href='https://wandb.ai/pizzi-1995517-sapienza-universit-di-roma/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pizzi-1995517-sapienza-universit-di-roma/huggingface' target=\"_blank\">https://wandb.ai/pizzi-1995517-sapienza-universit-di-roma/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pizzi-1995517-sapienza-universit-di-roma/huggingface/runs/7afa9mn3' target=\"_blank\">https://wandb.ai/pizzi-1995517-sapienza-universit-di-roma/huggingface/runs/7afa9mn3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/7820 : < :, Epoch 0.00/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (661) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/transformers/trainer.py:2560\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2553\u001b[39m context = (\n\u001b[32m   2554\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2556\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2557\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2558\u001b[39m )\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2560\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2563\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2564\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2565\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2566\u001b[39m ):\n\u001b[32m   2567\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2568\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/transformers/trainer.py:3736\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3733\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3735\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3736\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3738\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3740\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3741\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3742\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/transformers/trainer.py:3801\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3799\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3800\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3801\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3802\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3803\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:1288\u001b[39m, in \u001b[36mMobileBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1281\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1282\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1283\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1284\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1285\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1286\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmobilebert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1289\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1294\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1300\u001b[39m pooled_output = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1302\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:897\u001b[39m, in \u001b[36mMobileBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_hidden_states, output_attentions, return_dict)\u001b[39m\n\u001b[32m    890\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    891\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    894\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    895\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m embedding_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    900\u001b[39m encoder_outputs = \u001b[38;5;28mself\u001b[39m.encoder(\n\u001b[32m    901\u001b[39m     embedding_output,\n\u001b[32m    902\u001b[39m     attention_mask=extended_attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    906\u001b[39m     return_dict=return_dict,\n\u001b[32m    907\u001b[39m )\n\u001b[32m    908\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/MNLP/lib/python3.13/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:241\u001b[39m, in \u001b[36mMobileBertEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[39m\n\u001b[32m    239\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.position_embeddings(position_ids)\n\u001b[32m    240\u001b[39m token_type_embeddings = \u001b[38;5;28mself\u001b[39m.token_type_embeddings(token_type_ids)\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m embeddings = \u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m + token_type_embeddings\n\u001b[32m    242\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.LayerNorm(embeddings)\n\u001b[32m    243\u001b[39m embeddings = \u001b[38;5;28mself\u001b[39m.dropout(embeddings)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (661) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
