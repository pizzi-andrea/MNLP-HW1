{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95aaa2e5",
   "metadata": {},
   "source": [
    "# Analysis of Existing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3302adad",
   "metadata": {},
   "source": [
    "Primary analysis of how data is distributed in the existing datasets to understand what we can work on to enhance our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3eb214",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Base libs to read and show data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib as path\n",
    "from utils import extract_entity_id\n",
    "from datasets import load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f8e39",
   "metadata": {},
   "source": [
    "## Import Datasets and First Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc08ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Const values\n",
    "BASE_DIR = path.PosixPath('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV file\n",
    "dataset_t = load_dataset('sapienzanlp/nlp2025_hw1_cultural_dataset',)['train'].to_pandas()\n",
    "dataset_v = load_dataset('sapienzanlp/nlp2025_hw1_cultural_dataset')['validation'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some dataset entry\n",
    "dataset_t.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf49988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot values distribution to observer particular carachteristics\n",
    "# Test dataset\n",
    "category_dist_t = pd.Series.value_counts((dataset_t['category']))\n",
    "type_dist_t = pd.Series.value_counts((dataset_t['type']))\n",
    "sub_dist_t = pd.Series.value_counts((dataset_t['subcategory']))\n",
    "label_dist_t = pd.Series.value_counts((dataset_t['label']))\n",
    "# Validation dataset\n",
    "category_dist_v = pd.Series.value_counts((dataset_v['category']))\n",
    "type_dist_v = pd.Series.value_counts((dataset_v['type']))\n",
    "sub_dist_v = pd.Series.value_counts((dataset_v['subcategory']))\n",
    "label_dist_v = pd.Series.value_counts((dataset_v['label']))\n",
    "\n",
    "print(label_dist_t)\n",
    "\n",
    "# Gaussian distribution\n",
    "print(sub_dist_t)\n",
    "\n",
    "# Unbalanced    \n",
    "print(type_dist_t)\n",
    "\n",
    "# Category\n",
    "print(category_dist_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf58a05",
   "metadata": {},
   "source": [
    "## Category Analysis\n",
    "\n",
    "Look up to exploit some information on category, analyzing statistical aspects such as data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39187024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots category distribution\n",
    "plt.figure(figsize=(30,12))\n",
    "plt.title('Category Distribution')\n",
    "plt.xlabel('category')\n",
    "plt.ylabel('Num of Occurrences')\n",
    "plt.bar(category_dist_t.index, category_dist_t, 0.5, label='Train')\n",
    "\n",
    "plt.bar(category_dist_v.index, category_dist_v, 0.5, label='Test')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(loc='upper left', ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5daba",
   "metadata": {},
   "source": [
    "## Subcategory Analysis\n",
    "\n",
    "Look up to exploit some information on subcategory analyzing statistical aspects, such as data distribution and visual representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad955d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots subcategory distribution\n",
    "plt.figure(figsize=(14,20))\n",
    "plt.title('Subcategory Distribution')\n",
    "plt.ylabel('Subcategory')\n",
    "plt.xlabel('Num of Occurrences')\n",
    "plt.barh(sub_dist_t.index, sub_dist_t, 0.5, label='Train')\n",
    "plt.barh(sub_dist_v.index, sub_dist_v, 0.5, label='Test')\n",
    "plt.legend(loc='upper left', ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e642a",
   "metadata": {},
   "source": [
    "## Labels Analysis\n",
    "\n",
    "Check the number of classes to identify. This analysis is useful to find unbalanced data factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots labels distribution\n",
    "plt.figure()\n",
    "plt.title('Labels Distribution')\n",
    "plt.ylabel('Labels')\n",
    "plt.xlabel('Num of Occurrences')\n",
    "plt.barh(label_dist_t.index, label_dist_t, label='Train')\n",
    "plt.barh(label_dist_v.index, label_dist_v, label='Test')\n",
    "plt.legend(loc='upper left', ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d031e",
   "metadata": {},
   "source": [
    "## Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45156f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots type distribution\n",
    "plt.figure(figsize=(30,12))\n",
    "plt.title('Category Distribution')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Num of Occurrences')\n",
    "plt.bar(type_dist_t.index, type_dist_t, 0.5, label='Train')\n",
    "plt.bar(type_dist_v.index, type_dist_v, 0.5, label='Test')\n",
    "plt.legend(loc='upper left', ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d79fba2",
   "metadata": {},
   "source": [
    "## Labels Analysis wrt Categories, Subcategories, Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71833842",
   "metadata": {},
   "source": [
    "To further inspect the nature of our dataset, we have made an intra-classes analysis and found out that, with respect to labels distribution, some of the categories are unbalanced and bend towards one or two out of the three labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456cf1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agnostic = dataset_t.loc[dataset_t['label'] == 'cultural agnostic']\n",
    "rappresentative = dataset_t.loc[dataset_t['label'] == 'cultural representative']\n",
    "exclusive = dataset_t.loc[dataset_t['label'] == 'cultural exclusive']\n",
    "\n",
    "\n",
    "agnostic_fr_cat = pd.Series.value_counts((agnostic['category']))\n",
    "agnostic_fr_sub = pd.Series.value_counts((agnostic['subcategory']))\n",
    "agnostic_fr_type = pd.Series.value_counts((agnostic['type']))\n",
    "\n",
    "\n",
    "rappresentative_fr_cat = pd.Series.value_counts((rappresentative['category']))\n",
    "rappresentative_fr_sub = pd.Series.value_counts((rappresentative['subcategory']))\n",
    "rappresentative_fr_type = pd.Series.value_counts((rappresentative['type']))\n",
    "\n",
    "\n",
    "exclusive_fr_cat = pd.Series.value_counts((exclusive['category']))\n",
    "exclusive_fr_sub = pd.Series.value_counts((exclusive['subcategory']))\n",
    "exclusive_fr_type = pd.Series.value_counts((exclusive['type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212da337",
   "metadata": {},
   "source": [
    "### Labels and Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45107551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint categories\n",
    "all_categories = sorted(set(agnostic_fr_cat.index) |\n",
    "                        set(rappresentative_fr_cat.index) |\n",
    "                        set(exclusive_fr_cat.index))\n",
    "\n",
    "# Reindex to have complete and aligned dataframes\n",
    "agnostic_vals = agnostic_fr_cat.reindex(all_categories, fill_value=0)\n",
    "representative_vals = rappresentative_fr_cat.reindex(all_categories, fill_value=0)\n",
    "exclusive_vals = exclusive_fr_cat.reindex(all_categories, fill_value=0)\n",
    "\n",
    "# Total sum per category\n",
    "total = agnostic_vals + representative_vals + exclusive_vals\n",
    "\n",
    "# Decreasing order\n",
    "sorted_index = total.sort_values(ascending=False).index\n",
    "\n",
    "# Rearranges values according to sorted_index\n",
    "agnostic_vals = agnostic_vals[sorted_index]\n",
    "representative_vals = representative_vals[sorted_index]\n",
    "exclusive_vals = exclusive_vals[sorted_index]\n",
    "categories = sorted_index\n",
    "\n",
    "# Plot\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(categories))\n",
    "\n",
    "plt.figure(figsize=(30,12))\n",
    "plt.title('Category Distribution')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Num of Occurrences')\n",
    "\n",
    "plt.bar(index - bar_width, agnostic_vals, bar_width, label='Agnostic', color='skyblue')\n",
    "plt.bar(index, representative_vals, bar_width, label='Representative', color='lightgreen')\n",
    "plt.bar(index + bar_width, exclusive_vals, bar_width, label='Exclusive', color='lightcoral')\n",
    "\n",
    "plt.xticks(index, categories, rotation=45, ha='right')\n",
    "plt.legend(loc='upper left', ncols=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038dd76c",
   "metadata": {},
   "source": [
    "### Labels and Subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714cb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories = rappresentative_fr_type.index\n",
    "\n",
    "# Set the size of bars and the position\n",
    "bar_width = 0.17  # Size of the bars\n",
    "index = np.arange(len(subcategories))  # Positions of categories on x axis\n",
    "\n",
    "plt.figure(figsize=(30,12))\n",
    "plt.title('Category Distribution')\n",
    "plt.xlabel('Subcategory')\n",
    "plt.ylabel('Num of Occurrences')\n",
    "\n",
    "subcategories = agnostic_fr_sub.index\n",
    "index = np.arange(len(subcategories))\n",
    "plt.bar(index - bar_width, agnostic_fr_sub, bar_width, label='Agnostic', color='skyblue')\n",
    "subcategories = rappresentative_fr_sub.index\n",
    "index = np.arange(len(subcategories))\n",
    "plt.bar(index, rappresentative_fr_sub, bar_width, label='Representative', color='lightgreen')\n",
    "subcategories = exclusive_fr_sub.index\n",
    "index = np.arange(len(subcategories))\n",
    "plt.bar(index + bar_width, exclusive_fr_sub, bar_width, label='Exclusive', color='lightcoral')\n",
    "\n",
    "# Add labels on x axis\n",
    "plt.xticks(index, subcategories, rotation=45, ha='right')\n",
    "plt.legend(loc='upper left', ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c7917",
   "metadata": {},
   "source": [
    "### Labels and Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = rappresentative_fr_type.index\n",
    "\n",
    "# Set the size of bars and the position\n",
    "bar_width = 0.17  # Size of the bars\n",
    "index = np.arange(len(subcategories))  # Positions of categories on x axis\n",
    "\n",
    "plt.figure(figsize=(30,12))\n",
    "plt.title('Category Distribution')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Num of Occurrences')\n",
    "\n",
    "types = agnostic_fr_type.index\n",
    "index = np.arange(len(subcategories))\n",
    "plt.bar(index - bar_width, agnostic_fr_type, bar_width, label='Agnostic', color='skyblue')\n",
    "types = rappresentative_fr_type.index\n",
    "index = np.arange(len(subcategories))\n",
    "plt.bar(index, rappresentative_fr_type, bar_width, label='Representative', color='lightgreen')\n",
    "types = exclusive_fr_type.index\n",
    "index = np.arange(len(subcategories))\n",
    "plt.bar(index + bar_width, exclusive_fr_type, bar_width, label='Exclusive', color='lightcoral')\n",
    "\n",
    "# Add labels on x axis\n",
    "plt.xticks(index, types, rotation=45, ha='right')\n",
    "plt.legend(loc='upper left', ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c681f352",
   "metadata": {},
   "source": [
    "## Languages Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f033a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ccc0c",
   "metadata": {},
   "source": [
    "## Links Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d1aa64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd83b88",
   "metadata": {},
   "source": [
    "## Hyperlinks Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a1e81",
   "metadata": {},
   "source": [
    "### Parse of Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from random import shuffle\n",
    "\n",
    "def extract_relevant_links(response, maxlinks):\n",
    "    # Get the 'pages' section from the response JSON\n",
    "    data = response.json()\n",
    "    pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "    \n",
    "    valid_links = []\n",
    "\n",
    "    # Iterate through pages and their links\n",
    "    for page_id in pages:\n",
    "        page = pages[page_id]\n",
    "        links = page.get(\"links\", [])\n",
    "        print(f\"Number of Total Links Found: {len(links)}\")\n",
    "\n",
    "        # Shuffle the links to ensure randomness\n",
    "        shuffle(links)\n",
    "        \n",
    "        for link in links:\n",
    "            title = link[\"title\"]\n",
    "\n",
    "            # Filter out non-article links:\n",
    "            # Skip links that belong to special namespaces or are fragment links\n",
    "            if \":\" in title or \"#\" in title:  # Namespace or anchor links (e.g., 'Category:', 'File:', etc.)\n",
    "                continue\n",
    "            if not re.match(r'^[A-Za-z0-9 \\-()%]+$', title):  # Valid characters in titles\n",
    "                continue\n",
    "            if len(title) < 2 or title.lower() in ['edit', 'citation']:  # Skip trivial links like 'edit' or 'citation'\n",
    "                continue\n",
    "\n",
    "            # Exclude links that belong to non-article namespaces or are external links\n",
    "            if title.startswith((\"File:\", \"Category:\", \"Help:\", \"Portal:\", \"Special:\", \"Talk:\")):\n",
    "                continue\n",
    "            if re.match(r'^(http|https):\\/\\/', title):  # Skip external links (starting with 'http' or 'https')\n",
    "                continue\n",
    "\n",
    "            # Additional check to exclude links that might point to HTML elements or page structure\n",
    "            # This includes any links that are purely numbers, or other unwanted non-article titles\n",
    "            if title.isdigit():  # Filter out links that are only numbers (often page references or element IDs)\n",
    "                continue\n",
    "\n",
    "            # Only add unique, relevant links to the valid_links list\n",
    "            if title not in valid_links:\n",
    "                valid_links.append(title)\n",
    "\n",
    "            # Break early if we've reached the maximum number of links\n",
    "            if len(valid_links) >= maxlinks:\n",
    "                break\n",
    "        \n",
    "        # If we've found enough links, break out of the loop\n",
    "        if len(valid_links) >= maxlinks:\n",
    "            break\n",
    "    \n",
    "    print(f\"Number of Parsed Links Found: {len(valid_links)}\")\n",
    "    return valid_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "def BFS_Links(G: nx.DiGraph, title: str, limit: int , depth: int) -> nx.DiGraph:\n",
    "    \n",
    "    url = f\"https://en.wikipedia.org/w/api.php?action=query&titles={title}&prop=links&pllimit=max&format=json\"\n",
    "    try:\n",
    "        response = requests.get(url,\n",
    "        params={\n",
    "            \"action\": \"query\",\n",
    "            \"prop\": \"links\",\n",
    "            'titles': title,\n",
    "            \"pllimit\": \"max\",\n",
    "            \"plnamespace\": \"0\",  # Only namespace 0 to avoid useless links\n",
    "            \"format\": \"json\"\n",
    "        })\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error: {http_err}\")\n",
    "        return G\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Request timed out.\")\n",
    "        return G\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f\"Request error: {err}\")\n",
    "        return G\n",
    "    except ValueError as json_err:\n",
    "        print(f\"JSON parsing error: {json_err}\")\n",
    "        return G\n",
    "\n",
    "    # Add the base node if it's not already in the graph\n",
    "    base = title\n",
    "    if not G.has_node(base):\n",
    "        G.add_node(base, count=1)\n",
    "        G.nodes[base]['visited'] = False  # mark as not visited\n",
    "\n",
    "    # Extract links from the API response\n",
    "    links = extract_relevant_links(response, maxlinks=limit)\n",
    "    #print(links)\n",
    "    G.nodes[base]['visited'] = True  # mark base as visited\n",
    "    if len(links) == 0:\n",
    "        return G\n",
    "    \n",
    "    # Explore the links\n",
    "    for link in links:\n",
    "        if not G.has_node(link):\n",
    "            G.add_node(link, count=1)  # new node → count as first visit\n",
    "            G.nodes[link]['visited'] = False  # mark as not visited\n",
    "            G.add_edge(base, link)  # add edge between base and link\n",
    "        else:\n",
    "            G.nodes[link]['count'] += 1\n",
    "            #print(f\"Node '{link}' has been seen {G.nodes[link]['count']} times.\")\n",
    "\n",
    "    # Recursive call to explore all links\n",
    "    if not depth - 1:\n",
    "        return G\n",
    "    \n",
    "    for link in links:\n",
    "        print(f'====================[level {depth}]|[{base}]====================')\n",
    "        if not G.nodes[link]['visited']:\n",
    "            print(f\"visit{G.nodes[link]['count']}\")\n",
    "            G = BFS_Links(G, link, limit, depth - 1) # recursive call\n",
    "       \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ea424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Example starting point\n",
    "start_page = dataset_t['item'][56]\n",
    "qid = extract_entity_id(start_page)\n",
    "w = Wiki_Scrapter(qid)\n",
    "title = w.get_title()\n",
    "\n",
    "# Add the starting page to the graph\n",
    "# Recall the BFS_Links function\n",
    "G = BFS_Links(G, title, limit=10, depth=3)\n",
    "\n",
    "# Now we have a graph with nodes and edges representing Wikipedia pages and links between them\n",
    "\n",
    "# Example analysis: Draw the graph\n",
    "plt.figure(figsize=(10, 10))\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G,pos=pos, with_labels=True, node_size=50, node_color=\"skyblue\", font_size=10, font_weight=\"bold\")\n",
    "plt.title(f\"Graph of Wikipedia Links for '{start_page}'\")\n",
    "plt.show()\n",
    "\n",
    "# PageRank analysis (calculating importance of nodes)\n",
    "pagerank = nx.pagerank(G)\n",
    "print(\"PageRank of nodes:\", pagerank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
